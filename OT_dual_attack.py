# -*- coding: utf-8 -*-
"""OT-Dual-Cifar-new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tZux9JONT5Um3mubVEBrFOFywl7dff5P
"""

!nvidia-smi

'''ResNet in PyTorch.

For Pre-activation ResNet, see 'preact_resnet.py'.

Reference:
[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun
    Deep Residual Learning for Image Recognition. arXiv:1512.03385
'''
import torch
import torch.nn as nn
import torch.nn.functional as F
import os
import argparse
import gc
import imutils
import cv2


import torch.optim as optim
import torchvision
import torchvision.models as models
import torch.backends.cudnn as cudnn

import math
import sys



from torchvision import transforms
from tqdm.autonotebook import tqdm
from torch.utils.data import DataLoader
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
import inspect

import matplotlib.pyplot as plt
import numpy as np



from PIL import Image
from torch.optim.lr_scheduler import StepLR
from google.colab import drive


drive.mount('/content/gdrive/')






class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != self.expansion*planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(self.expansion*planes)
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = F.relu(out)
        return out


class Bottleneck(nn.Module):
    expansion = 4

    def __init__(self, in_planes, planes, stride=1):
        super(Bottleneck, self).__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)
        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(self.expansion*planes)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != self.expansion*planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(self.expansion*planes)
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = F.relu(self.bn2(self.conv2(out)))
        out = self.bn3(self.conv3(out))
        out += self.shortcut(x)
        out = F.relu(out)
        return out


class ResNet(nn.Module):
    def __init__(self, block, num_blocks, num_classes=10):
        super(ResNet, self).__init__()
        # self.in_planes = 64
        self.in_planes = 64 
        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
        self.linear = nn.Linear(512*block.expansion, num_classes)

    def _make_layer(self, block, planes, num_blocks, stride):
        strides = [stride] + [1]*(num_blocks-1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_planes, planes, stride))
            self.in_planes = planes * block.expansion
        return nn.Sequential(*layers)

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = F.avg_pool2d(out, 4)
        out = out.view(out.size(0), -1)
        out = self.linear(out)
        return out


def ResNet18():
    return ResNet(BasicBlock, [2,2,2,2])

def ResNet34():
    return ResNet(BasicBlock, [3,4,6,3])

def ResNet50(num_classes=10):
    return ResNet(Bottleneck, [3,4,6,3], num_classes=num_classes)

def ResNet101():
    return ResNet(Bottleneck, [3,4,23,3])

def ResNet152():
    return ResNet(Bottleneck, [3,8,36,3])


def test():
    net = ResNet18()
    y = net(torch.randn(1,3,32,32))
    print(y.size())

# test()



device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')



"""Basic Helper Functions"""

# def __init__(self, name=None):
#     self.name = name

def __enter__(self):
    self.tstart = time.time()

def __exit__(self, type, value, traceback):
    if self.name:
        print('[%s]' % self.name,)
    print('Elapsed: %s' % (time.time() - self.tstart))

def wasserstein_cost( p, kernel_size,n ):
    print('p is ',p)
    C = torch.zeros(kernel_size**2,kernel_size**2)
    xs, ys = torch.meshgrid([torch.arange(kernel_size), torch.arange(kernel_size)])
    a = xs.reshape(xs.size(0)**2,-1)
    b = ys.reshape(ys.size(0)**2,-1)
    c = torch.randn(xs.size(0)**2,2)*0
    c[:,0] = a.reshape(-1)
    c[:,1] = b.reshape(-1)
    for i in range(int(kernel_size)**2):
      for j in range(int(kernel_size)**2):
        C[i,j] = ( abs(c[i,0] - c[j,0])**p + abs(c[i,1] - c[j,1])**p)**(1/p)
    return C    

    

def _expand(X, shape): 
    return X.view(*X.size()[:-1], *shape)

def unflatten2(X):
    n = X.size(-1)
    k = int(math.sqrt(n))
    return _expand(X,(k,k))

def unsqueeze3(X):
    return X.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)

def _expand_filter(X, nfilters , index ): 
    sizes = list(-1 for _ in range(X.dim()))
    sizes[-index] = nfilters
    return X.expand(*sizes)


def _unfold(x, kernel_size, padding=None): 
    size = x.size()
    if len(size) > 4: 
        x = x.contiguous().view(-1, *size[-3:])
    out = F.unfold(x, kernel_size, padding=kernel_size//2)
    if len(size) > 4: 
        out = out.view(*size[:-3], *out.size()[1:])
    return out

def collapse2(X): 
    return X.view(*X.size()[:-2], -1)

def _mm(A,x, shape): 
    kernel_size = A.size(-1) # 5
    nfilters = shape[1]  # 1
    unfolded = _unfold(x, kernel_size, padding=kernel_size//2).transpose(-1,-2)     
    unfolded = _expand(unfolded, (A.size(-3),A.size(-2)*A.size(-1))).transpose(-2,-3) #( 4 , 1 , 28*28  , 25 )
    out = torch.matmul(unfolded, collapse2(A.contiguous()).unsqueeze(-1)).squeeze(-1) #(4 , 1 , 25 , 1)
    return unflatten2(out)  #(4 , 1, 28*28 , 1) -> #(4 * 1 , 28 , 28)
#(728*728) * (728 , 4)
def any_nan(X): 
    return (X != X).any().item()

def print_cifar( pixels ):
    if pixels.shape[0] == 1:
      plt.imshow( pixels[0] , cmap = 'gray' )
      plt.show()
      return
    #print('Pixel shape' , pixels.shape)
    pixels = (pixels.transpose(1,2,0)*255).astype(np.uint8)
    # fig = plt.figure(figsize=(3,3)) 
    # ax = fig.add_subplot(131) 
    # ax.imshow(pixels,interpolation='nearest')
    # plt.show()
    # plt.axis('off')
    img = plt.imshow(pixels, interpolation='nearest')
    plt.axis('off')
  


def print_temp( pixels  ):
    torch.clamp(pixels , min = 0 , max = 1)
    pixels = pixels[0].cpu().detach().numpy()
    print_cifar(pixels)

"""Calculate ∇H∗qk(uk)"""

#function to calculate ∇H∗qk(uk) K - (4 , 1 , 5 , 5) alpha - (4 , 1 ,28 , 28)
def del_H( q , alpha , K  ):
  q1 = q/( _mm(K , alpha , alpha.size()) + 1e-6 )
  q1 = alpha* _mm(K , q1 , q1.size())
  return q1  
def alph( u , gamma):
  return torch.exp(u/gamma )

def new_del_H( q , alpha , K  ):
  return alpha*torch.matmul( q/(torch.matmul(alpha , K.t())) , K.t()) 
def alph( u , gamma):
  return torch.exp(u/gamma )

# class ResNet(torch.nn.Module):
#     def __init__(self, module):
#         super().__init__()
#         self.module = module

#     def forward(self, inputs):
#         return self.module(inputs) + inputs

def dual_attack( marginals , image ,t,batch_idx,thold,targets_attack,targets, W , C , gamma , delta , theeta , tau,eta):
  shape = marginals.size()
  N = shape[0]
  flag = True  
  flag1 = True 
  marginals = marginals.reshape(N,shape[1],-1)
  #print('max marginal is',torch.max(marginals))
  n = marginals.size(-1)
  #print('n is',n)
  W = W.reshape(N,shape[1],-1)        #flattening W
  #print('shape of W is',W.size())
  imgshape = image.size()     
  image = image.reshape(-1)  #flattening image
  with torch.no_grad():
    Vecone = W.new_ones((n))        # X -> ( u(k's) , v)  initialized with ones
    Vecone = Vecone.unsqueeze(-1)
    alpha = 0*W.new_ones((N,shape[1],n))
    #print('shape of alpha is',alpha.size())
    beta = 0*W.new_ones((N,shape[1],n))
    z = W
    #print('max z is',torch.max(z))
    K =  torch.exp(-C/eta).to(device)
    K = K.unsqueeze(0)
    K = K.repeat(N,shape[1],1,1)
    #print('size of K is ------',K.size())
    
    eps = 0.01
    co = 0
   
    delta = 0.05
    
    #while torch.sum(torch.mul(B/torch.sum(B),K),(1,2,3))>delta: #uncomment for attack
    while True: #comment after adversarial training
      
      z[z < 0] = 0 
      al = torch.diag_embed(torch.exp(alpha)/eta)
      be = torch.diag_embed(torch.exp(beta)/eta)
      B = torch.matmul(al,K)
      B = torch.matmul(B,be)
      
      #B = B/torch.sum(B)  
      #print('B size',B.size())
      r = torch.matmul(B,Vecone)
      Btrans = torch.transpose(B,2,3)
      #print('Btrans size',Btrans.size())
      q = torch.matmul(Btrans,Vecone)
      r[r < 0] = 0 
      q[q < 0] = 0  
      r = r.squeeze(-1) 
      q = q.squeeze(-1)  
      if co%2 == 0:
          alpha = (alpha/tau + torch.log(marginals + eps) - torch.log(r+eps))*eta*tau/(eta+tau)
          if any_nan(alpha):
            print('alpha got nan at itration ' , co )
      else:      
          beta = (beta/tau + torch.log(z+eps) - torch.log(q+eps))*eta*tau/(eta+tau)
          if any_nan(beta):
            print('beta got nan at itration ' , co )
            break
          # tz = z      
          # tz = W + (tau/gamma)*torch.exp(-beta/tau)  
          # dif = (torch.abs(tz.reshape(N,-1) - marginals.reshape(N,-1))).squeeze(-1)  
          # #print('OT is', torch.sum(torch.mul(B/torch.sum(B),K),(1,2,3)))  
          z[:,:,:] = W[:,:,:] + (tau/gamma)*torch.exp(-beta[:,:,:]/tau)
          # if shape[1]==1:
          Wbak = z.reshape(shape[0],shape[1],shape[2],shape[3])
          Wmin, Wind = Wbak.view(-1,shape[2]*shape[3]).min(axis=1)
          Wmin = Wmin.unsqueeze(-1).unsqueeze(-1)
          # print('size of z',z.size(),'size of Wmin',Wmin.size())
          z = z.add(-Wmin.reshape(shape[0],shape[1],-1))  
          OT = torch.sum(torch.mul(B/torch.sum(B),K),(1,2,3))
          # print('OT is....=',OT)
          if any_nan(z):
            print('z got nan at itration ' , co )
            print(z)
            break
      
      
    
      if co>thold and co%2 == 0:
        print('here........')
        break 
      elif co>thold:
        al = torch.diag_embed(torch.exp(alpha)/eta)
        be = torch.diag_embed(torch.exp(beta)/eta)
        B = torch.matmul(al,K)
        B = torch.matmul(B,be)
        break
      co+=1
    
    OT = torch.sum(torch.mul(B/torch.sum(B),K),(1,2,3))
    
    Z = z.reshape(shape[0],shape[1],shape[2],shape[3])
    # if shape[1]==1:
    Zmin, Zind = Z.view(-1,shape[2]*shape[3]).min(axis=1)
    Zmin = Zmin.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)
    Z = Z.add(-Zmin.reshape(shape[0],shape[1],1,1))
    
    M = marginals.reshape(shape[0],shape[1],shape[2],shape[3])

    # replace red and blue channel with original
    # Z[:,0,:,:] = M[:,0,:,:]
    # Z[:,2,:,:] = M[:,2,:,:]
    origimage = M[0].cpu().detach().numpy()
    # print('max of origimage',np.max(origimage),'min of origimage',np.min(origimage))
    origimage = 255*(origimage/np.max(origimage))

    advimage = Z[0].cpu().detach().numpy()
    # print('max of advimage',np.max(advimage),'min of advimage',np.min(advimage))
    advimage = advimage - np.min(advimage)
    # print('max of advimage',np.max(advimage),'min of advimage',np.min(advimage))
    advimage = 255*(advimage/np.max(advimage))

    diffimage = np.abs(origimage - advimage)
    diffimage = 255*(diffimage/np.max(diffimage))
    
    
    pixels = (origimage[0]).astype(np.uint8)
    # img = plt.imshow(pixels, interpolation='nearest')
    # plt.axis('off')

    pixels = (advimage[0]).astype(np.uint8)
    # img = plt.imshow(pixels, interpolation='nearest')
    # plt.axis('off')
  
    OTpixels = B[0].cpu().numpy()
   
    
       
  # del alpha,beta
  # gc.collect()  
  return Z, OT, B/torch.max(B)   #returning p



def attack(XX ,yy ,  net ,C,total,batch_idx, targets,thold,alpha, p = 2 ,  kernel_size=5, maxiters= 10, 
         xmin=0, xmax=1, normalize=lambda x: x, verbose=0, 
             norm='linfinity' ,   gamma = 0.5 , delta = 0.01 , theeta = 1 , tau = 0.1 , eta = 100  ): 
    N = XX.size(0)
    X = XX#specify later
    y = yy
    #normalization = XX.view(N,3,-1).sum(-1).view(N,3,1,1)  #Recheck if needed
    #normalization = XX.view(N,-1).sum(-1).view(N,1,1,1)  #Recheck if needed
    normalization = 255
    X_ = X.clone()
    X_best = X.clone()
    err_best = err = net(normalize(X)).max(1)[1] != y
    t = 0
    eps = 0.01
    pix = X_.cpu().detach().numpy()
  
    while True: 
        X_.requires_grad = True
        opt = optim.SGD([X_], lr=0.1)
        loss = nn.CrossEntropyLoss()(net(normalize(X_)),y)
        opt.zero_grad()
        loss.backward()

        with torch.no_grad(): 
            # take a step
            
            if norm == 'linfinity': 
                X_[~err] += alpha*torch.sign(X_.grad[~err])
            elif norm == 'l2': 
                X_[~err] += (alpha*X_.grad/(X_.grad.view(X.size(0),-1).norm(dim=1).view(X.size(0),1,1,1)) + eps)[~err]
            else: 
                raise ValueError("Unknown norm")

            
            Xall, OT, D = dual_attack(XX.clone()*normalization , 
                                     X.clone()*normalization, t,batch_idx,thold,y,targets,
                                     X_.detach()*normalization , C , 
                                     gamma , delta , theeta , tau,eta)
            X_[~err] = Xall[~err]
            X_[~err] = X_[~err]/normalization
           
            
            X_ = torch.clamp(X_, min=xmin, max=xmax)  #Recheck later if clamp is needed or not
            
            
            err = (net(normalize(X_)).max(1)[1] != y)
            predicted_class = net(normalize(X_)).max(1)[1]
            flag = True
            
            err_rate = err.sum().item()
             
            if err_rate > err_best.sum().item():
                X_best = X_.clone() 
                err_best = err
            
            t += 1
            if err_rate == N or t == maxiters: 
                break

    torch.cuda.empty_cache()
    return X_best, y,err_best



"""Formulation"""

# Commented out IPython magic to ensure Python compatibility.
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

print('==> Preparing data..')
transform_train = transforms.Compose([
    transforms.ToTensor(),])

transform_test = transforms.Compose([
    transforms.RandomAffine(0,translate=(0,0)),                            
    transforms.ToTensor(), ])

trainset = torchvision.datasets.MNIST(root='/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/dataset/data/', train=True, download=  True, transform=transform_train)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True, num_workers=2)   # MNIST

dig = 5 #The digit to attack
testset = torchvision.datasets.MNIST(root='/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/dataset/data/', train=False, download= True , transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size= 200, shuffle= False )


print('==> Building model..')

class Flatten(nn.Module):
    def forward(self, x):
        return x.view(x.size(0), -1)

#uncomment for mnist

net = nn.Sequential(
        nn.Conv2d(1, 16, 4, stride=2, padding=1),
        nn.ReLU(),
        nn.Conv2d(16, 32, 4, stride=2, padding=1),
        nn.ReLU(),
        nn.Flatten(),
        nn.Linear(32*7*7,100),
        nn.ReLU(),
        nn.Linear(100, 10)
    )


net = net.to(device)

alpha = 0.02
norm = 'linfinity'


model_name = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/mnist_vanilla.pth'


binarize = False

print('==> loading model {}'.format(model_name))



d = torch.load(model_name)
if 'state_dict' in d: 
    net.load_state_dict(d['state_dict'][0])    
elif 'robust' in model_name: 
    net.load_state_dict(d)
else: 
    net.load_state_dict(d['net'])


criterion = nn.CrossEntropyLoss()

def testmnist():
    netattack.eval()
    test_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(testloader):
            inputs, targets = inputs.to(device), targets.to(device)
            if binarize:
                inputs = (inputs >= 0.5).float()
            outputs = netattack(inputs)
            loss = criterion(outputs, targets)

            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    acc = 100.*correct/total
    print('Accuracy = ', acc )




normalize = lambda x: x #comment for cifar
p = 1
kernel_size = 28
C = wasserstein_cost(p=p, kernel_size= kernel_size, n =  kernel_size)

def test_attackmnist(): 
    netattack.eval()
    net.eval()
    test_loss = 0
    correct = 0
    total = 0
    batchOT = 0
    for batch_idx, (inputs, targets) in enumerate(testloader):
        inputs, targets = inputs.to(device), targets.to(device)
        targets_attack = targets # should add or subtract for targeted attack
        if binarize: 
            inputs = (inputs >= 0.5).float()
        N = inputs.size(0)
        total += targets.size(0)
        inputs_pgd,y,  _ = attack(torch.clamp((inputs),min=0), 
                                 targets_attack, netattack,  C, total,batch_idx,targets,
                                 p= p, alpha=alpha , norm=norm ,
                                 maxiters= 10 ,thold =10 , normalize=normalize ,
                                 gamma = .5 ,
                                 kernel_size= 784 , delta = 0.003 , 
                                 theeta = 100 , tau =.01 , eta = .001)
                                #  eta = .25 )

        outputs_pgd = net(inputs_pgd)
        loss = criterion(outputs_pgd, y)

        test_loss += loss.item()
        _, predicted = outputs_pgd.max(1)
        
    
        correct += predicted.eq(targets).sum().item()
        print('Batch ' , batch_idx , 'Loss = ' , test_loss/(batch_idx+1) , 'Accuracy = ' , 100.*correct/total  )
        # print('original labels:predicted labels',targets,predicted)
        if batch_idx==0:
          break

        acc = 100.*correct/total
#         if batch_idx > 0:
#           break
    print('final accuracy = ' , 100.*correct/total)

#print('==> Evaluating model..')

# # print('==> Attacking model..')

test_attackmnist()


# Training
start_epoch = 0 # start from epoch 0 or last checkpoint epoch

optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)


# scheduler = StepLR(optimizer, step_size=5, gamma=0.5)
for pr in net.parameters(): 
    pr.requires_grad = True
def train(epoch):
    print('\nEpoch: %d' % epoch)
    net.train()
    train_loss = 0
    correct = 0
    nominal_correct = 0
    total_epsilon = 0
    total = 0
    batchOT = 0
    for batch_idx, (inputs, targets) in enumerate(trainloader):
        inputs, targets = inputs.to(device), targets.to(device)
        targets_attack = targets
        inputs_pgd,y, OT, _ = attack(torch.clamp((inputs),min=0), 
                                 targets_attack, net,  C, total,batch_idx,targets,
                                 p= p, alpha=alpha , norm=norm ,
                                 maxiters= 20 ,thold = 10 , normalize=normalize ,
                                 gamma = .5 ,
                                 kernel_size= 784 , delta = 0.003 , 
                                 theeta = 100 , tau = .01 , 
                                 eta = .001 )
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        with torch.no_grad(): 
            outputs_nominal = net(inputs)
            _, predicted_nominal = outputs_nominal.max(1)
            nominal_correct += predicted_nominal.eq(targets).sum().item()

            train_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
           
            
        print(batch_idx, len(trainloader), 'Loss: %.3f | Adv Acc: %.3f%% (%d/%d) | Acc: %.3f%% (%d/%d) '
#             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total, 
                100.*nominal_correct/total, nominal_correct, total))
        # if batch_idx == 2:
        #   break
   
    advacc = np.round(100.*correct/total,2)
    acc = np.round(100.*nominal_correct/total,2)
    state = {
        'net': net.state_dict(),
        'acc': acc,
        'advacc': advacc,
        'epoch': epoch,
    }
    torch.save(state, checkpoint_file.format(epoch,advacc,acc))
    


