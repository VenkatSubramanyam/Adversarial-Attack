{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "OT-Dual-Cifar-new.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa1638c7131a45acbd4ce0510ce1327b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b03f50a264654b999e72909a8bd6b540",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_98fecd2b0de24329ae200fdb4c3d30bf",
              "IPY_MODEL_408d80e47b554302a8a6ca75f6b41709"
            ]
          }
        },
        "b03f50a264654b999e72909a8bd6b540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98fecd2b0de24329ae200fdb4c3d30bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21454eb223754465a2b36578129b53b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18e612af3a5040f792cac4fd842136b4"
          }
        },
        "408d80e47b554302a8a6ca75f6b41709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_af6dd7ec24194c8ca6fa756360854a56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:06&lt;00:00, 27240419.29it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89e985c18e8a4a60b95311a6c3e5538e"
          }
        },
        "21454eb223754465a2b36578129b53b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18e612af3a5040f792cac4fd842136b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af6dd7ec24194c8ca6fa756360854a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89e985c18e8a4a60b95311a6c3e5538e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jmMJOeqiMS7",
        "outputId": "58089645-c24b-4f14-c818-702aa4a5d8e7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 23 06:41:28 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    38W / 300W |   1345MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YztORdN2Sn4"
      },
      "source": [
        "'''ResNet in PyTorch.\n",
        "\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        # self.in_planes = 64\n",
        "        self.in_planes = 64 \n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3,4,6,3])\n",
        "\n",
        "def ResNet50(num_classes=10):\n",
        "    return ResNet(Bottleneck, [3,4,6,3], num_classes=num_classes)\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3,4,23,3])\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3,8,36,3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1,3,32,32))\n",
        "    print(y.size())\n",
        "\n",
        "# test()\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3FmTJCCNJYg",
        "outputId": "fe2d07c7-0a45-45e0-a661-8e40870330bd"
      },
      "source": [
        "import collections\n",
        "orderedDict = collections.OrderedDict()\n",
        "\n",
        "\n",
        "from collections import OrderedDict\n",
        "model = nn.Sequential(OrderedDict([\n",
        "        ('conv1',nn.Conv2d(1, 16, 4, stride=2, padding=1)),\n",
        "        ('relu1',nn.ReLU()),\n",
        "        ('conv2',nn.Conv2d(16, 32, 4, stride=2, padding=1)),\n",
        "        ('relu2',nn.ReLU()),\n",
        "        ('flatten',nn.Flatten()),\n",
        "        ('linear1',nn.Linear(32*7*7,100)),\n",
        "        ('relu3',nn.ReLU()),\n",
        "        ('linear2',nn.Linear(100, 10))\n",
        "     ]))\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear1): Linear(in_features=1568, out_features=100, bias=True)\n",
            "  (relu3): ReLU()\n",
            "  (linear2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruPPsh2zPwT6"
      },
      "source": [
        "# def zero_gradients(x):\n",
        "#      if isinstance(x, torch.Tensor):\n",
        "#          if x.grad is not None:\n",
        "#              x.grad.detach_()\n",
        "#              x.grad.data.zero_()\n",
        "#      elif isinstance(x, container_abcs.Iterable):\n",
        "#          for elem in x:\n",
        "#              zero_gradients(elem)\n",
        "# # \n",
        "# !python /content/gdrive/MyDrive/improved_wasserstein/attack_mnist_baseline.py\n",
        "\n"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqsCGRyy5Jsr",
        "outputId": "8de143f1-6fc6-46be-d7ea-1fa8b0d8c6db"
      },
      "source": [
        "# !pip install torchattacks\n",
        "# !pip install geomloss\n",
        "!rm -rf /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST\n",
        "!rm -rf /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST.zip\n",
        "!mkdir /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST\n",
        "\n",
        "!python /content/gdrive/MyDrive/improved_wasserstein/attack_mnist_baseline.py\n",
        "# !zip -r /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST.zip /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "==> Building model..\n",
            "==> regularization set to 1000\n",
            "norm is linfinity epsilon = 0.001 epsilon-factor =  0.001 alpha= 0.1\n",
            "batch_idx 0 acc= 54.5\n",
            "Runtime of the program is 52.3708598613739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-YUM3g9EApy",
        "outputId": "6bd6befa-af9b-4c96-f6dd-97ba7262f238"
      },
      "source": [
        "#https://colab.research.google.com/github/kjamithash/Pytorch_DeepLearning_Experiments/\n",
        "#blob/master/FashionMNIST_ResNet_TransferLearning.ipynb#scrollTo=Lsbcb_WgFx3c\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "import time\n",
        "from tqdm.autonotebook import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import inspect\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# class MnistResNet(nn.Module):\n",
        "#   def __init__(self, in_channels=1):\n",
        "#     super(MnistResNet, self).__init__()\n",
        "\n",
        "#     # Load a pretrained resnet model from torchvision.models in Pytorch\n",
        "#     self.model = resnet18()\n",
        "\n",
        "#     # Change the input layer to take Grayscale image, instead of RGB images. \n",
        "#     # Hence in_channels is set as 1 or 3 respectively\n",
        "#     # original definition of the first layer on the ResNet class\n",
        "#     # self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "#     self.model.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    \n",
        "#     # Change the output layer to output 10 classes instead of 1000 classes\n",
        "#     num_ftrs = self.model.fc.in_features\n",
        "#     self.model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     return self.model(x)\n",
        "\n",
        "\n",
        "model = nn.Sequential(OrderedDict([\n",
        "        ('conv1',nn.Conv2d(1, 16, 4, stride=2, padding=1)),\n",
        "        ('relu1',nn.ReLU()),\n",
        "        ('conv2',nn.Conv2d(16, 32, 4, stride=2, padding=1)),\n",
        "        ('relu2',nn.ReLU()),\n",
        "        ('flatten',nn.Flatten()),\n",
        "        ('linear1',nn.Linear(32*7*7,100)),\n",
        "        ('relu3',nn.ReLU()),\n",
        "        ('linear2',nn.Linear(100, 10))\n",
        "     ]))\n",
        "net = model\n",
        "# model_state_dict = torch.load(\"/content/gdrive/MyDrive/Colab_Notebooks/MnistCNN\")\n",
        "# model.load_state_dict(model_state_dict)\n",
        "\n",
        "\n",
        "# input = torch.randn((16,1,244,244))\n",
        "# output = my_resnet(input)\n",
        "# print(output.shape)\n",
        "\n",
        "# print(my_resnet)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\") \n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "# def get_data_loaders(train_batch_size, val_batch_size):\n",
        "fashion_mnist = torchvision.datasets.FashionMNIST(download=True, train=True, root=\".\").train_data.float()\n",
        "\n",
        "data_transform = transforms.Compose([ transforms.ToTensor(), \n",
        "                                      transforms.RandomAffine(30,translate=(0.0,0.0)), \n",
        "                                      transforms.Normalize((fashion_mnist.mean()/255,), (fashion_mnist.std()/255,))])\n",
        "\n",
        "trainloader = DataLoader(torchvision.datasets.FashionMNIST(download=True, root=\".\", transform=data_transform, train=True),\n",
        "                          batch_size=1, shuffle=True)\n",
        "testset = torchvision.datasets.FashionMNIST(root=\".\", train=False, download= True , transform=data_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size= 200, shuffle= False )\n",
        "\n",
        "val_loader = DataLoader(torchvision.datasets.FashionMNIST(download=False, root=\".\", transform=data_transform, train=False),\n",
        "                        batch_size=1, shuffle=False)\n",
        "\n",
        "    \n",
        "    # return train_loader, val_loader, testloader\n",
        "\n",
        "\n",
        "mu = (fashion_mnist.mean()/255).to(device)\n",
        "std = (fashion_mnist.std()/255).to(device)\n",
        "unnormalize = lambda x: x*std + mu\n",
        "normalize = lambda x: (x-mu)/std\n",
        "def calculate_metric(metric_fn, true_y, pred_y):\n",
        "    if \"average\" in inspect.getfullargspec(metric_fn).args:\n",
        "        return metric_fn(true_y, pred_y, average=\"macro\")\n",
        "    else:\n",
        "        return metric_fn(true_y, pred_y)\n",
        "    \n",
        "def print_scores(p, r, f1, a, batch_size):\n",
        "    for name, scores in zip((\"precision\", \"recall\", \"F1\", \"accuracy\"), (p, r, f1, a)):\n",
        "        print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")\n",
        "\n",
        "# model:\n",
        "model = model.to(device)\n",
        "\n",
        "# params you need to specify:\n",
        "epochs = 10\n",
        "\n",
        "# Dataloaders\n",
        "# train_loader, val_loader, testloader = get_data_loaders(batch_size, batch_size)\n",
        "\n",
        "# loss function and optimiyer\n",
        "loss_function = nn.CrossEntropyLoss() # your loss function, cross entropy works well for multi-class problems\n",
        "\n",
        "# optimizer, I've used Adadelta, as it wokrs well without any magic numbers\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4) # Using Karpathy's learning rate constant\n",
        "\n",
        "start_ts = time.time()\n",
        "\n",
        "losses = []\n",
        "batches = len(trainloader)\n",
        "val_batches = len(val_loader)\n",
        "\n",
        "# loop for every epoch (training + evaluation)\n",
        "# for epoch in range(epochs):\n",
        "#     total_loss = 0\n",
        "\n",
        "#     # progress bar (works in Jupyter notebook too!)\n",
        "#     progress = tqdm(enumerate(train_loader), desc=\"Loss: \", total=batches)\n",
        "\n",
        "#     # ----------------- TRAINING  -------------------- \n",
        "#     # set model to training\n",
        "#     model.train()\n",
        "#     total = 0\n",
        "#     for i, data in progress:\n",
        "#         X, y = data[0].to(device), data[1].to(device)\n",
        "#         targets_attack = y\n",
        "#         batch_idx = i\n",
        "#         targets = y\n",
        "#         total += targets.size(0)\n",
        "#         # training step for single batch\n",
        "#         inputs_pgd,y,  _ = attack(torch.clamp(unnormalize(X),min=0), \n",
        "#                                  targets_attack, model,  C, total,batch_idx,targets,\n",
        "#                                  p= p, alpha=alpha , norm=norm ,\n",
        "#                                  maxiters= 10 ,thold =10 , normalize=normalize ,\n",
        "#                                  gamma = .5 ,\n",
        "#                                  kernel_size= 784 , delta = 0.003 , \n",
        "#                                  theeta = 100 , tau =.01 , eta = .001)\n",
        "#                                 #  eta = .25 )\n",
        "#         model.zero_grad()\n",
        "#         outputs = model(normalize(inputs_pgd))\n",
        "#         loss = loss_function(outputs, y)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # getting training quality data\n",
        "#         current_loss = loss.item()\n",
        "#         total_loss += current_loss\n",
        "\n",
        "#         # updating progress bar\n",
        "#         progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i+1)))\n",
        "        \n",
        "#     # releasing unceseccary memory in GPU\n",
        "#     if torch.cuda.is_available():\n",
        "#         torch.cuda.empty_cache()\n",
        "    \n",
        "#     # ----------------- VALIDATION  ----------------- \n",
        "#     val_losses = 0\n",
        "#     precision, recall, f1, accuracy = [], [], [], []\n",
        "    \n",
        "#     # set model to evaluating (testing)\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         for i, data in enumerate(val_loader):\n",
        "#             X, y = data[0].to(device), data[1].to(device)\n",
        "\n",
        "#             outputs = model(X) # this get's the prediction from the network\n",
        "\n",
        "#             val_losses += loss_function(outputs, y)\n",
        "\n",
        "#             predicted_classes = torch.max(outputs, 1)[1] # get class from network's prediction\n",
        "            \n",
        "#             # calculate P/R/F1/A metrics for batch\n",
        "#             for acc, metric in zip((precision, recall, f1, accuracy), \n",
        "#                                    (precision_score, recall_score, f1_score, accuracy_score)):\n",
        "#                 acc.append(\n",
        "#                     calculate_metric(metric, y.cpu(), predicted_classes.cpu())\n",
        "#                 )\n",
        "          \n",
        "#     print(f\"Epoch {epoch+1}/{epochs}, training loss: {total_loss/batches}, validation loss: {val_losses/val_batches}\")\n",
        "#     print_scores(precision, recall, f1, accuracy, val_batches)\n",
        "#     losses.append(total_loss/batches) # for plotting learning curve\n",
        "# print(f\"Training time: {time.time()-start_ts}s\")\n",
        "\n",
        "            \n",
        "# torch.save(model.state_dict(), \"/content/gdrive/MyDrive/Colab_Notebooks/MnistCNN\")    \n",
        "# model = MnistCNN()\n",
        "# model_state_dict = torch.load(\"/content/gdrive/MyDrive/Colab_Notebooks/MnistCNN\")\n",
        "# model.load_state_dict(model_state_dict)\n",
        "\n",
        "\n"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seSY0NUvJTzX"
      },
      "source": [
        ""
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYNtamCjMJww"
      },
      "source": [
        "# # '''\n",
        "# # Properly implemented ResNet-s for CIFAR10 as described in paper [1].\n",
        "# # The implementation and structure of this file is hugely influenced by [2]\n",
        "# # which is implemented for ImageNet and doesn't have option A for identity.\n",
        "# # Moreover, most of the implementations on the web is copy-paste from\n",
        "# # torchvision's resnet and has wrong number of params.\n",
        "# # Proper ResNet-s for CIFAR10 (for fair comparision and etc.) has following\n",
        "# # number of layers and parameters:\n",
        "# # name      | layers | params\n",
        "# # ResNet20  |    20  | 0.27M\n",
        "# # ResNet32  |    32  | 0.46M\n",
        "# # ResNet44  |    44  | 0.66M\n",
        "# # ResNet56  |    56  | 0.85M\n",
        "# # ResNet110 |   110  |  1.7M\n",
        "# # ResNet1202|  1202  | 19.4m\n",
        "# # which this implementation indeed has.\n",
        "# # Reference:\n",
        "# # [1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "# #     Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "# # [2] https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
        "# # If you use this implementation in you work, please don't forget to mention the\n",
        "# # author, Yerlan Idelbayev.\n",
        "# # '''\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch.nn.init as init\n",
        "\n",
        "# from torch.autograd import Variable\n",
        "\n",
        "# __all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56_custom', 'resnet110', 'resnet1202']\n",
        "\n",
        "# def _weights_init(m):\n",
        "#     classname = m.__class__.__name__\n",
        "#     #print(classname)\n",
        "#     if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "#         init.kaiming_normal_(m.weight)\n",
        "\n",
        "# class LambdaLayer(nn.Module):\n",
        "#     def __init__(self, lambd):\n",
        "#         super(LambdaLayer, self).__init__()\n",
        "#         self.lambd = lambd\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.lambd(x)\n",
        "\n",
        "\n",
        "# class BasicBlock(nn.Module):\n",
        "#     expansion = 1\n",
        "\n",
        "#     def __init__(self, in_planes, planes, stride=1, option='A'):\n",
        "#         super(BasicBlock, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(planes)\n",
        "#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "#         self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "#         self.shortcut = nn.Sequential()\n",
        "#         if stride != 1 or in_planes != planes:\n",
        "#             if option == 'A':\n",
        "#                 \"\"\"\n",
        "#                 For CIFAR10 ResNet paper uses option A.\n",
        "#                 \"\"\"\n",
        "#                 self.shortcut = LambdaLayer(lambda x:\n",
        "#                                             F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
        "#             elif option == 'B':\n",
        "#                 self.shortcut = nn.Sequential(\n",
        "#                      nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "#                      nn.BatchNorm2d(self.expansion * planes)\n",
        "#                 )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = F.relu(self.bn1(self.conv1(x)))\n",
        "#         out = self.bn2(self.conv2(out))\n",
        "#         out += self.shortcut(x)\n",
        "#         out = F.relu(out)\n",
        "#         return out\n",
        "\n",
        "\n",
        "# class ResNet(nn.Module):\n",
        "#     def __init__(self, block, num_blocks, num_classes=10):\n",
        "#         super(ResNet, self).__init__()\n",
        "#         self.in_planes = 16\n",
        "\n",
        "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(16)\n",
        "#         self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "#         self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "#         self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "#         self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "#         self.apply(_weights_init)\n",
        "\n",
        "#     def _make_layer(self, block, planes, num_blocks, stride):\n",
        "#         strides = [stride] + [1]*(num_blocks-1)\n",
        "#         layers = []\n",
        "#         for stride in strides:\n",
        "#             layers.append(block(self.in_planes, planes, stride))\n",
        "#             self.in_planes = planes * block.expansion\n",
        "\n",
        "#         return nn.Sequential(*layers)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = F.relu(self.bn1(self.conv1(x)))\n",
        "#         out = self.layer1(out)\n",
        "#         out = self.layer2(out)\n",
        "#         out = self.layer3(out)\n",
        "#         out = F.avg_pool2d(out, out.size()[3])\n",
        "#         out = out.view(out.size(0), -1)\n",
        "#         out = self.linear(out)\n",
        "#         return out\n",
        "\n",
        "\n",
        "# def resnet20():\n",
        "#     return ResNet(BasicBlock, [3, 3, 3])\n",
        "\n",
        "\n",
        "# def resnet32():\n",
        "#     return ResNet(BasicBlock, [5, 5, 5])\n",
        "\n",
        "\n",
        "# def resnet44():\n",
        "#     return ResNet(BasicBlock, [7, 7, 7])\n",
        "\n",
        "\n",
        "# def resnet56_custom():\n",
        "#     return ResNet(BasicBlock, [9, 9, 9])\n",
        "\n",
        "\n",
        "# def resnet110():\n",
        "#     return ResNet(BasicBlock, [18, 18, 18])\n",
        "\n",
        "\n",
        "# def resnet1202():\n",
        "#     return ResNet(BasicBlock, [200, 200, 200])\n",
        "\n",
        "\n",
        "# def test(net):\n",
        "#     import numpy as np\n",
        "#     total_params = 0\n",
        "\n",
        "#     for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
        "#         total_params += np.prod(x.data.numpy().shape)\n",
        "#     print(\"Total number of params\", total_params)\n",
        "#     print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     for net_name in __all__:\n",
        "#         if net_name.startswith('resnet'):\n",
        "#             print(net_name)\n",
        "#             test(globals()[net_name]())\n",
        "#             print()"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUFf7fcxTG6O"
      },
      "source": [
        ""
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOfMy4inW7qg",
        "outputId": "032bf1c4-3a6c-48f7-c36f-ae77bab0e5b9"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def mat_min(*args):\n",
        "  maatmin = np.min(mat,axis=(1,2))\n",
        "  return maatmin\n",
        "\n",
        "mat = np.random.randn(2,2,2)\n",
        "print('ma',mat)\n",
        "mmin = mat_min(mat)\n",
        "print(mmin)\n",
        "\n",
        "mat = np.array([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
        "print('new',mat)\n",
        "mmin = mat_min(mat)\n",
        "print(mmin)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ma [[[-0.27755712 -0.98029187]\n",
            "  [ 0.26539887 -1.34501095]]\n",
            "\n",
            " [[ 1.21617634 -2.01023592]\n",
            "  [-0.17088618 -0.03967752]]]\n",
            "[-1.34501095 -2.01023592]\n",
            "new [[[1 2]\n",
            "  [3 4]]\n",
            "\n",
            " [[5 6]\n",
            "  [7 8]]]\n",
            "[1 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t--2WyeHzWwH"
      },
      "source": [
        "# import numpy as np\n",
        "# import time\n",
        "# import mouse\n",
        "\n",
        "# while True:\n",
        "#   random_row = np.random.random_sample()*100\n",
        "#   random_col = np.random.random_sample()*10\n",
        "#   random_time = np.random.random_sample()*np.random.random_sample() * 100\n",
        "#   mouse.move(random_row, random_col, absolute=False, duration=0.2)\n",
        "#   mouse.move(-random_row, -random_col, absolute=False, duration = 0.2)\n",
        "#   mouse.LEFT\n",
        "#   time.sleep(random_time)\n",
        "\n"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcTHfVai69F9"
      },
      "source": [
        "# !unzip '/content/gdrive/MyDrive/Colab_Notebooks/PyTorch_CIFAR10-master.zip' -d '/content/gdrive/MyDrive/Colab_Notebooks/PyTorch_CIFAR10-master'\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CXEo4GvGt0Y"
      },
      "source": [
        "#!ls /content/gdrive/MyDrive/Colab_Notebooks/Images\n",
        "\n",
        "#!ls /content/gdrive/MyDrive/projected_sinkhorn/checkpoints/"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjzSU68oooOF"
      },
      "source": [
        "!rm -rf /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST\n",
        "!rm -rf /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST.zip\n",
        "!mkdir /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST\n",
        "\n",
        "!rm -rf /content/gdrive/MyDrive/Colab_Notebooks/Images/fashionMNIST\n",
        "!rm -rf /content/gdrive/MyDrive/Colab_Notebooks/Images/fashionMNIST.zip\n",
        "!mkdir /content/gdrive/MyDrive/Colab_Notebooks/Images/fashionMNIST\n",
        "\n",
        "!rm -rf /content/gdrive/MyDrive/Colab_Notebooks/Images/CIFAR\n",
        "!rm -rf /content/gdrive/MyDrive/Colab_Notebooks/Images/CIFAR.zip\n",
        "!mkdir /content/gdrive/MyDrive/Colab_Notebooks/Images/CIFAR\n",
        "#!rm /content/gdrive/MyDrive/projected_sinkhorn/checkpoints/mnist_dual_epoch_*.pth"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9AtybxJowvD"
      },
      "source": [
        "# !ls /content/gdrive/MyDrive/Colab_Notebooks/projected_sinkhorn-wong/checkpoints\n",
        "#!ls /content/gdrive/MyDrive/improved_wasserstein/checkpoints\n",
        "# !ls /content/gdrive/MyDrive/projected_sinkhorn/checkpoints"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJHtFKDWJwlS"
      },
      "source": [
        "# import os\n",
        "# os.chdir('/content/gdrive/wong_sinkhorn/projected_sinkhorn-master/')\n",
        "# !pwd"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa1XdGaxHLTf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMGy7KOIKwDP"
      },
      "source": [
        "# !python setup.py install"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTUEhcVxIMxE"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm4ouJcCLNCi"
      },
      "source": [
        "#!cp -r '/content/gdrive/MyDrive/improved_wasserstein/checkpoints/.' '/content/gdrive/MyDrive/Colab_Notebooks/projected_sinkhorn-wong/checkpoints'\n",
        "#!python attack_mnist.py"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9THj-woRWlZ5"
      },
      "source": [
        ""
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcNHopL-ZR9a"
      },
      "source": [
        ""
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPdtu0nXZVem"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58l4Rb8QXIMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47fe10f7-d096-4b4d-fcf7-ae7a4191d55e"
      },
      "source": [
        "import time\n",
        "\n",
        "# starting time\n",
        "start = time.time()\n",
        "\n",
        "# program body starts\n",
        "for i in range(200):\n",
        "    print(i)\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end - start}\")\n"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "Runtime of the program is 0.018764972686767578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKq44TpUgh0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9186b786-0594-4a50-b682-7d4a01d23169"
      },
      "source": [
        "#!python /content/gdrive/MyDrive/improved_wasserstein/attack_cifar_baseline.py\n",
        "!python /content/gdrive/MyDrive/improved_wasserstein/attack_mnist_baseline.py\n",
        "# !zip -r /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST.zip /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "==> Building model..\n",
            "==> regularization set to 1000\n",
            "norm is linfinity epsilon = 0.001 epsilon-factor =  0.001 alpha= 0.1\n",
            "batch_idx 0 acc= 54.5\n",
            "Runtime of the program is 52.59829831123352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q064fT6qg-Y9"
      },
      "source": [
        "# !python /content/gdrive/MyDrive/Colab_Notebooks/projected_sinkhorn-wong/attack_mnist.py\n",
        "# !zip -r /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST.zip /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JStG6culGso",
        "outputId": "97d29577-035c-4e8b-92df-d30341bc17ea"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import math\n",
        "import sys\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import time\n",
        "from google.colab import drive\n",
        "#drive.flush_and_unmount()\n",
        "\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "# drive.mount('/content/gdrive/')\n",
        "#!mkdir '/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/checkpoints'\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/checkpoints/')\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/dataset/')\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/')\n",
        " \n",
        "#from __future__ import print_function\n",
        "import timeit \n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import argparse\n",
        "import gc\n",
        "import imutils\n",
        "import cv2\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()\n",
        "path = '/content/gdrive/MyDrive/Colab_Notebooks/Images/fashionMNIST'\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5OI1CqyD_Xb"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZxk6M61YZHf"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJbhNWXiDYy8",
        "outputId": "fbc06545-6890-4d86-8dde-650f2cfa3913"
      },
      "source": [
        "a = torch.randn(5,3,28,28)\n",
        "za = a.view(-1,784)\n",
        "# print(a)\n",
        "# b=a.view(-1,2*2).min(axis=1)\n",
        "# print(b)\n",
        "Zmin, Zind = a.view(-1,784).min(axis=1)\n",
        "Zmin = Zmin.unsqueeze(-1).unsqueeze(-1)\n",
        "# Zmin = Zmin.transpose(1,0)\n",
        "print(Zmin.size())\n",
        "# K = Zmin.repeat(1,1,1,1)\n",
        "# K=K.transpose(3,0)\n",
        "# print(K.size())\n",
        "za = za.add(-Zmin)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPXQHMV0DYy-"
      },
      "source": [
        ""
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBm8kfmJDYy-"
      },
      "source": [
        ""
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwH7osxDDYy-",
        "outputId": "4849d2e6-c58c-4a9a-f288-b0fb773c38d2"
      },
      "source": [
        "c = np.random.rand(2,3,2,2)\n",
        "print(c.shape[1])"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLQQjyOTDYy_"
      },
      "source": [
        "# c = np.random.rand(2,1,2,2)\n",
        "# d = np.array([1,2])\n",
        "# print(c)\n",
        "# f = c/d.reshape(2,1,1,1)\n",
        "# print(f)\n",
        "# c = torch.rand(2,2)\n",
        "# print(c)\n",
        "# d = c.unsqueeze(0)\n",
        "# al = d.repeat(2,3,1,1)\n",
        "# print(al)\n",
        "\n",
        "# a = torch.randn(2,5)\n",
        "# print(a)\n",
        "# b,c=torch.max(a,dim=1)\n",
        "# g= torch.max(b)\n",
        "# print(g)\n",
        "\n",
        "\n",
        "# c = torch.randn(tensor.size()).bool()\n",
        "# print(c.size())\n",
        "# c[0,3] = False\n",
        "# val = c==True\n",
        "# print(torch.sum(val))\n",
        "\n",
        "\n",
        "\n",
        "# a = torch.randn(2,2,2,2)\n",
        "# b = torch.randn(2,2,2,2)\n",
        "# c = torch.subtract(a,b)\n",
        "# print(a,b,c)\n",
        "\n",
        "\n",
        "# g = torch.abs(a.reshape(4,-1) - b.reshape(4,-1))\n",
        "# d=g[:,1]\n",
        "# print('size',d.size())\n",
        "# print('max is',torch.max(d))\n",
        "# ind = d <.7\n",
        "# print(ind)\n",
        "# t = a\n",
        "# print('t',t)\n",
        "# t[ind,:,:] = 1\n",
        "# print('t after = 1',t)\n",
        "# a[ind,:,:] = t[ind,:,:]\n",
        "# print('a = t',a)\n",
        "\n",
        "    \n",
        "#print(torch.sum(torch.mul(c,d),(1,2,3)))\n",
        "# al = torch.diag_embed(c)\n",
        "# print(al)\n",
        "\n",
        "#c = np.random.rand(2,3,2,2)\n",
        "#print(c)\n",
        "# pixmax = np.max(c, axis = (2,3))\n",
        "# print('pixmax',pixmax)\n",
        "# pixmax = pixmax.reshape(2,3,1,1)\n",
        "# print('pixmax  resh',pixmax)\n",
        "# c = c/pixmax\n",
        "# print('c o',c)\n",
        "\n",
        "# d = c.view(2,3,-1)\n",
        "\n",
        "# f = d.sum(-1)\n",
        "\n",
        "# g = f.view(2,3,1,1)\n",
        "# print(g)\n",
        "# normalization = c.view(2,3,-1).sum(-1).view(2,3,1,1)\n",
        "# print(c/normalization)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIAZqP0mlzp1"
      },
      "source": [
        "Basic Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QP3qvp1DYy_"
      },
      "source": [
        "\n",
        "# def __init__(self, name=None):\n",
        "#     self.name = name\n",
        "\n",
        "def __enter__(self):\n",
        "    self.tstart = time.time()\n",
        "\n",
        "def __exit__(self, type, value, traceback):\n",
        "    if self.name:\n",
        "        print('[%s]' % self.name,)\n",
        "    print('Elapsed: %s' % (time.time() - self.tstart))"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8xBg_2rpweQ"
      },
      "source": [
        "def wasserstein_cost( p, kernel_size,n ):\n",
        "    print('p is ',p)\n",
        "    C = torch.zeros(kernel_size**2,kernel_size**2)\n",
        "    xs, ys = torch.meshgrid([torch.arange(kernel_size), torch.arange(kernel_size)])\n",
        "    a = xs.reshape(xs.size(0)**2,-1)\n",
        "    b = ys.reshape(ys.size(0)**2,-1)\n",
        "    c = torch.randn(xs.size(0)**2,2)*0\n",
        "    c[:,0] = a.reshape(-1)\n",
        "    c[:,1] = b.reshape(-1)\n",
        "    for i in range(int(kernel_size)**2):\n",
        "      for j in range(int(kernel_size)**2):\n",
        "        C[i,j] = ( abs(c[i,0] - c[j,0])**p + abs(c[i,1] - c[j,1])**p)**(1/p)\n",
        "    return C    \n",
        "#     C = torch.zeros(kernel_size**2,kernel_size**2)\n",
        "#     for i in range(kernel_size**2):\n",
        "#       for j in range(kernel_size**2):\n",
        "#         tix = i/n\n",
        "#         tiy = i%n\n",
        "#         tjx = j/n\n",
        "#         tjy = j%n\n",
        "#         C[i,j] = ( abs(tix - tjx)**p + abs(tiy - tjy)**p)**(1/p)\n",
        "#     print(C)    \n",
        "#     return C\n",
        "    \n",
        "\n",
        "def _expand(X, shape): \n",
        "    return X.view(*X.size()[:-1], *shape)\n",
        "\n",
        "def unflatten2(X):\n",
        "    n = X.size(-1)\n",
        "    k = int(math.sqrt(n))\n",
        "    return _expand(X,(k,k))\n",
        "\n",
        "def unsqueeze3(X):\n",
        "    return X.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "def _expand_filter(X, nfilters , index ): \n",
        "    sizes = list(-1 for _ in range(X.dim()))\n",
        "    sizes[-index] = nfilters\n",
        "    return X.expand(*sizes)\n",
        "\n",
        "\n",
        "def _unfold(x, kernel_size, padding=None): \n",
        "    size = x.size()\n",
        "    if len(size) > 4: \n",
        "        x = x.contiguous().view(-1, *size[-3:])\n",
        "    out = F.unfold(x, kernel_size, padding=kernel_size//2)\n",
        "    if len(size) > 4: \n",
        "        out = out.view(*size[:-3], *out.size()[1:])\n",
        "    return out\n",
        "\n",
        "def collapse2(X): \n",
        "    return X.view(*X.size()[:-2], -1)\n",
        "\n",
        "def _mm(A,x, shape): \n",
        "    kernel_size = A.size(-1) # 5\n",
        "    nfilters = shape[1]  # 1\n",
        "    unfolded = _unfold(x, kernel_size, padding=kernel_size//2).transpose(-1,-2)     \n",
        "    unfolded = _expand(unfolded, (A.size(-3),A.size(-2)*A.size(-1))).transpose(-2,-3) #( 4 , 1 , 28*28  , 25 )\n",
        "    out = torch.matmul(unfolded, collapse2(A.contiguous()).unsqueeze(-1)).squeeze(-1) #(4 , 1 , 25 , 1)\n",
        "    return unflatten2(out)  #(4 , 1, 28*28 , 1) -> #(4 * 1 , 28 , 28)\n",
        "#(728*728) * (728 , 4)\n",
        "def any_nan(X): \n",
        "    return (X != X).any().item()\n",
        "\n",
        "def print_cifar( pixels ):\n",
        "    if pixels.shape[0] == 1:\n",
        "      plt.imshow( pixels[0] , cmap = 'gray' )\n",
        "      plt.show()\n",
        "      return\n",
        "    #print('Pixel shape' , pixels.shape)\n",
        "    pixels = (pixels.transpose(1,2,0)*255).astype(np.uint8)\n",
        "    # fig = plt.figure(figsize=(3,3)) \n",
        "    # ax = fig.add_subplot(131) \n",
        "    # ax.imshow(pixels,interpolation='nearest')\n",
        "    # plt.show()\n",
        "    # plt.axis('off')\n",
        "    img = plt.imshow(pixels, interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "  \n",
        "\n",
        "\n",
        "def print_temp( pixels  ):\n",
        "    torch.clamp(pixels , min = 0 , max = 1)\n",
        "    pixels = pixels[0].cpu().detach().numpy()\n",
        "    print_cifar(pixels)\n",
        "\n"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePVFGNacl4c7"
      },
      "source": [
        "Calculate âˆ‡Hâˆ—qk(uk)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHhA2ICoDpi6"
      },
      "source": [
        "#function to calculate âˆ‡Hâˆ—qk(uk) K - (4 , 1 , 5 , 5) alpha - (4 , 1 ,28 , 28)\n",
        "def del_H( q , alpha , K  ):\n",
        "  q1 = q/( _mm(K , alpha , alpha.size()) + 1e-6 )\n",
        "  q1 = alpha* _mm(K , q1 , q1.size())\n",
        "  return q1  \n",
        "def alph( u , gamma):\n",
        "  return torch.exp(u/gamma )"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJpLMyDjbhF-"
      },
      "source": [
        "def new_del_H( q , alpha , K  ):\n",
        "  return alpha*torch.matmul( q/(torch.matmul(alpha , K.t())) , K.t()) \n",
        "def alph( u , gamma):\n",
        "  return torch.exp(u/gamma )"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMGYbsokCM7p"
      },
      "source": [
        "# class ResNet(torch.nn.Module):\n",
        "#     def __init__(self, module):\n",
        "#         super().__init__()\n",
        "#         self.module = module\n",
        "\n",
        "#     def forward(self, inputs):\n",
        "#         return self.module(inputs) + inputs"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCmpeRYMDYzC"
      },
      "source": [
        "def dual_attack( marginals , image ,t,batch_idx,thold,targets_attack,targets, W , C , gamma , delta , theeta , tau,eta):\n",
        "  shape = marginals.size()\n",
        "  N = shape[0]\n",
        "  flag = True  \n",
        "  flag1 = True \n",
        "  marginals = marginals.reshape(N,shape[1],-1)\n",
        "  #print('max marginal is',torch.max(marginals))\n",
        "  n = marginals.size(-1)\n",
        "  #print('n is',n)\n",
        "  W = W.reshape(N,shape[1],-1)        #flattening W\n",
        "  #print('shape of W is',W.size())\n",
        "  imgshape = image.size()     \n",
        "  image = image.reshape(-1)  #flattening image\n",
        "  with torch.no_grad():\n",
        "    Vecone = W.new_ones((n))        # X -> ( u(k's) , v)  initialized with ones\n",
        "    Vecone = Vecone.unsqueeze(-1)\n",
        "    alpha = 0*W.new_ones((N,shape[1],n))\n",
        "    #print('shape of alpha is',alpha.size())\n",
        "    beta = 0*W.new_ones((N,shape[1],n))\n",
        "    z = W\n",
        "    #print('max z is',torch.max(z))\n",
        "    K =  torch.exp(-C/eta).to(device)\n",
        "    K = K.unsqueeze(0)\n",
        "    K = K.repeat(N,shape[1],1,1)\n",
        "    #print('size of K is ------',K.size())\n",
        "    \n",
        "    eps = 0.01\n",
        "    co = 0\n",
        "   \n",
        "    delta = 0.05\n",
        "    \n",
        "    #while torch.sum(torch.mul(B/torch.sum(B),K),(1,2,3))>delta: #uncomment for attack\n",
        "    while True: #comment after adversarial training\n",
        "      \n",
        "      z[z < 0] = 0 \n",
        "      al = torch.diag_embed(torch.exp(alpha)/eta)\n",
        "      be = torch.diag_embed(torch.exp(beta)/eta)\n",
        "      B = torch.matmul(al,K)\n",
        "      B = torch.matmul(B,be)\n",
        "      \n",
        "      #B = B/torch.sum(B)  \n",
        "      #print('B size',B.size())\n",
        "      r = torch.matmul(B,Vecone)\n",
        "      Btrans = torch.transpose(B,2,3)\n",
        "      #print('Btrans size',Btrans.size())\n",
        "      q = torch.matmul(Btrans,Vecone)\n",
        "      r[r < 0] = 0 \n",
        "      q[q < 0] = 0  \n",
        "      r = r.squeeze(-1) \n",
        "      q = q.squeeze(-1)  \n",
        "      if co%2 == 0:\n",
        "          alpha = (alpha/tau + torch.log(marginals + eps) - torch.log(r+eps))*eta*tau/(eta+tau)\n",
        "          if any_nan(alpha):\n",
        "            print('alpha got nan at itration ' , co )\n",
        "      else:      \n",
        "          beta = (beta/tau + torch.log(z+eps) - torch.log(q+eps))*eta*tau/(eta+tau)\n",
        "          if any_nan(beta):\n",
        "            print('beta got nan at itration ' , co )\n",
        "            break\n",
        "          # tz = z      \n",
        "          # tz = W + (tau/gamma)*torch.exp(-beta/tau)  \n",
        "          # dif = (torch.abs(tz.reshape(N,-1) - marginals.reshape(N,-1))).squeeze(-1)  \n",
        "          # #print('OT is', torch.sum(torch.mul(B/torch.sum(B),K),(1,2,3)))  \n",
        "          z[:,:,:] = W[:,:,:] + (tau/gamma)*torch.exp(-beta[:,:,:]/tau)\n",
        "          # if shape[1]==1:\n",
        "          Wbak = z.reshape(shape[0],shape[1],shape[2],shape[3])\n",
        "          Wmin, Wind = Wbak.view(-1,shape[2]*shape[3]).min(axis=1)\n",
        "          Wmin = Wmin.unsqueeze(-1).unsqueeze(-1)\n",
        "          # print('size of z',z.size(),'size of Wmin',Wmin.size())\n",
        "          z = z.add(-Wmin.reshape(shape[0],shape[1],-1))  \n",
        "          OT = torch.sum(torch.mul(B/torch.sum(B),K),(1,2,3))\n",
        "          # print('OT is....=',OT)\n",
        "          if any_nan(z):\n",
        "            print('z got nan at itration ' , co )\n",
        "            print(z)\n",
        "            break\n",
        "      \n",
        "      \n",
        "    \n",
        "      if co>thold and co%2 == 0:\n",
        "        print('here........')\n",
        "        break \n",
        "      elif co>thold:\n",
        "        al = torch.diag_embed(torch.exp(alpha)/eta)\n",
        "        be = torch.diag_embed(torch.exp(beta)/eta)\n",
        "        B = torch.matmul(al,K)\n",
        "        B = torch.matmul(B,be)\n",
        "        break\n",
        "      co+=1\n",
        "    \n",
        "    OT = torch.sum(torch.mul(B/torch.sum(B),K),(1,2,3))\n",
        "    \n",
        "    Z = z.reshape(shape[0],shape[1],shape[2],shape[3])\n",
        "    # if shape[1]==1:\n",
        "    Zmin, Zind = Z.view(-1,shape[2]*shape[3]).min(axis=1)\n",
        "    Zmin = Zmin.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "    Z = Z.add(-Zmin.reshape(shape[0],shape[1],1,1))\n",
        "    \n",
        "    M = marginals.reshape(shape[0],shape[1],shape[2],shape[3])\n",
        "\n",
        "    # replace red and blue channel with original\n",
        "    # Z[:,0,:,:] = M[:,0,:,:]\n",
        "    # Z[:,2,:,:] = M[:,2,:,:]\n",
        "    origimage = M[0].cpu().detach().numpy()\n",
        "    # print('max of origimage',np.max(origimage),'min of origimage',np.min(origimage))\n",
        "    origimage = 255*(origimage/np.max(origimage))\n",
        "\n",
        "    advimage = Z[0].cpu().detach().numpy()\n",
        "    # print('max of advimage',np.max(advimage),'min of advimage',np.min(advimage))\n",
        "    advimage = advimage - np.min(advimage)\n",
        "    # print('max of advimage',np.max(advimage),'min of advimage',np.min(advimage))\n",
        "    advimage = 255*(advimage/np.max(advimage))\n",
        "\n",
        "    diffimage = np.abs(origimage - advimage)\n",
        "    diffimage = 255*(diffimage/np.max(diffimage))\n",
        "    \n",
        "    \n",
        "    pixels = (origimage[0]).astype(np.uint8)\n",
        "    # img = plt.imshow(pixels, interpolation='nearest')\n",
        "    # plt.axis('off')\n",
        "\n",
        "    pixels = (advimage[0]).astype(np.uint8)\n",
        "    # img = plt.imshow(pixels, interpolation='nearest')\n",
        "    # plt.axis('off')\n",
        "  \n",
        "    OTpixels = B[0].cpu().numpy()\n",
        "   \n",
        "    # OTpixels = np.log(OTpixels+1e-20)\n",
        "    # print('sum=',np.sum(OTpixels),'max=',np.max(OTpixels),'min=',np.min(OTpixels))\n",
        "    # OTpixels = OTpixels - np.min(OTpixels)\n",
        "    # plt.imshow(OTpixels[0], cmap=\"gray\",vmin=0, vmax=60) \n",
        "    # plt.show() \n",
        "    # print('sum=',np.sum(OTpixels),'max=',np.max(OTpixels),'min=',np.min(OTpixels))\n",
        "    # OTpixels = OTpixels/np.max(OTpixels)\n",
        "    \n",
        "    # OTpixels = 255*OTpixels\n",
        "    # print('sum=',np.sum(OTpixels),'max=',np.max(OTpixels),'min=',np.min(OTpixels))\n",
        "\n",
        "    \n",
        "    if origimage.shape[1] == 32:\n",
        "      cv2.imwrite(os.path.join(path, 'orig'+str(batch_idx)+'.jpg'),(origimage.transpose(1,2,0)).astype(int))\n",
        "      cv2.imwrite(os.path.join(path, 'attack_target'+'_'+str(batch_idx)+'targets_'+str(targets[0])+'targets_attack'+str(targets_attack[0])+'.jpg'),(advimage.transpose(1,2,0)).astype(int))\n",
        "    else:\n",
        "      cv2.imwrite(os.path.join(path, 'OT'+str(batch_idx)+'.jpg'),(OTpixels[0]).astype(int))\n",
        "      # cv2.imwrite(os.path.join(path, 'orig'+str(batch_idx)+'.jpg'),(origimage[0]).astype(int))\n",
        "      # cv2.imwrite(os.path.join(path, 'attack_'+str(batch_idx)+'_'+'gamma_'+str(gamma)+'_'+'.jpg'),(advimage[0]).astype(int))\n",
        "    \n",
        "    # cv2.imwrite(os.path.join(path, 'error_'+str(batch_idx)+str(t)+'.jpg'),(diffimage.transpose(1,2,0)).astype(int))\n",
        "    # cv2.imwrite(os.path.join(path, 'OT_'+str(batch_idx)+str(t)+'.jpg'),(255*OTpixels[0]).astype(int))\n",
        "\n",
        "       \n",
        "  # del alpha,beta\n",
        "  # gc.collect()  \n",
        "  return Z, OT, B/torch.max(B)   #returning p"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO6kHKj2DYzD"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def attack(XX ,yy ,  net ,C,total,batch_idx, targets,thold,alpha, p = 2 ,  kernel_size=5, maxiters= 10, \n",
        "         xmin=0, xmax=1, normalize=lambda x: x, verbose=0, \n",
        "             norm='linfinity' ,   gamma = 0.5 , delta = 0.01 , theeta = 1 , tau = 0.1 , eta = 100  ): \n",
        "    N = XX.size(0)\n",
        "    X = XX#specify later\n",
        "    y = yy\n",
        "    #path = '/Users/madhushree/Desktop/drive/MyDrive/projected_sinkhorn/dataset/MNIST/'\n",
        "    #normalization = XX.view(N,3,-1).sum(-1).view(N,3,1,1)  #Recheck if needed\n",
        "    #normalization = XX.view(N,-1).sum(-1).view(N,1,1,1)  #Recheck if needed\n",
        "    normalization = 255\n",
        "    #print('normalization',normalization)\n",
        "    X_ = X.clone()\n",
        "    X_best = X.clone()\n",
        "    err_best = err = net(normalize(X)).max(1)[1] != y\n",
        "    t = 0\n",
        "    eps = 0.01\n",
        "    pix = X_.cpu().detach().numpy()\n",
        "    yuniform = 0.1*torch.ones(N,10).to(device)\n",
        "    yuniform[:,0]=0.1\n",
        "    yuniform = yuniform/torch.sum(yuniform,0)\n",
        "    # print('y',y,'yuniform',yuniform)\n",
        "    #print('max of X is',np.max(pix))\n",
        "    while True: \n",
        "        X_.requires_grad = True\n",
        "\n",
        "        # # codde for sinkhorn loss\n",
        "        # H_ = net(normalize(X_))\n",
        "        # # H_.requires_grad = True\n",
        "        # optSink = optim.SGD([X_], lr=0.1)\n",
        "        # lossSinkhorn = SamplesLoss(loss=\"sinkhorn\", p=1, blur=.5)\n",
        "        # # print('H size',H_.size(),'yuniform size',yuniform.size())\n",
        "        # Lsink = lossSinkhorn(H_,yuniform)\n",
        "        # optSink.zero_grad()\n",
        "        # Lsink.backward()\n",
        "\n",
        "        \n",
        "        opt = optim.SGD([X_], lr=0.1)\n",
        "        loss = nn.CrossEntropyLoss()(net(normalize(X_)),y)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad(): \n",
        "            # take a step\n",
        "            \n",
        "            if norm == 'linfinity': \n",
        "                X_[~err] += alpha*torch.sign(X_.grad[~err])\n",
        "            elif norm == 'l2': \n",
        "                X_[~err] += (alpha*X_.grad/(X_.grad.view(X.size(0),-1).norm(dim=1).view(X.size(0),1,1,1)) + eps)[~err]\n",
        "            else: \n",
        "                raise ValueError(\"Unknown norm\")\n",
        "\n",
        "            \n",
        "            # project onto ball\n",
        "            #X_[~err] = ( dual_attack( XX.clone()*normalization , \n",
        "#                                      X.clone()*normalization ,thold, \n",
        "#                                      X_.detach()*normalization , C , \n",
        "#                                      gamma , delta , theeta , tau,eta)/\n",
        "#                                      normalization)[~err]\n",
        "           \n",
        "            # X_[~err], OT, D = dual_attack(XX.clone()*normalization , \n",
        "            #                          X.clone()*normalization,thold, \n",
        "            #                          X_.detach()*normalization , C , \n",
        "            #                          gamma , delta , theeta , tau,eta)\n",
        "            Xall, OT, D = dual_attack(XX.clone()*normalization , \n",
        "                                     X.clone()*normalization, t,batch_idx,thold,y,targets,\n",
        "                                     X_.detach()*normalization , C , \n",
        "                                     gamma , delta , theeta , tau,eta)\n",
        "            X_[~err] = Xall[~err]\n",
        "            X_[~err] = X_[~err]/normalization\n",
        "            #X_[err] = X_[err]/normalization\n",
        "            #What Normalizations to perform ?\n",
        "            # print('Showing original image at iter',t)\n",
        "            pixelsorig = X[0].cpu().detach().numpy()\n",
        "            # #pixelsorig1 = X[1].cpu().detach().numpy()\n",
        "            # # print_cifar(pixelsorig)\n",
        "            # img = plt.imshow((pixelsorig.transpose(1,2,0)*255).astype(np.uint8), interpolation='nearest')\n",
        "            # plt.axis('off')\n",
        "\n",
        "            \n",
        "            # print('X_ mins....',np.min(X_[0][0].cpu().detach().numpy()))\n",
        "            # print('X_ max....',np.max(X_[0][0].cpu().detach().numpy()))\n",
        "            # print('X_ sum....',np.mean(X_[0][0].cpu().detach().numpy()))\n",
        "            pix = X_.cpu().detach().numpy()\n",
        "            pixmax = np.max(pix, axis = (2,3))\n",
        "            #print(pixmax)\n",
        "            pixmin = np.min(pix, axis = (2,3))\n",
        "            #--------\n",
        "            pixm = pixmax[~err.cpu()]\n",
        "            #print('pixm is......',pixm,'pixmax is..',pixmax)\n",
        "            pixm = pixm.reshape(pixm.shape[0],pixm.shape[1],1,1)\n",
        "            Xa= X_[~err].cpu()/pixm\n",
        "            # X_[~err] = Xa.to(device)\n",
        "            #print(err)\n",
        "            #---------\n",
        "            # print('Showing adver image at second',t)\n",
        "            # pixelsadv = X_[0].cpu().detach().numpy()\n",
        "            # pixelsadv1 = X_[1].cpu().detach().numpy()\n",
        "            # print_cifar(pixelsadv)\n",
        "\n",
        "            #print('pixmax is',pixmax)\n",
        "\n",
        "\n",
        "            X_ = torch.clamp(X_, min=xmin, max=xmax)  #Recheck later if clamp is needed or not\n",
        "            \n",
        "            \n",
        "       \n",
        "            # print('Showing adv image at iter ',t)\n",
        "            pixelsadv = X_[0].cpu().detach().numpy()\n",
        "            # # print_cifar(pixelsadv)\n",
        "            # img = plt.imshow((pixelsadv.transpose(1,2,0)*255).astype(np.uint8), interpolation='nearest')\n",
        "            # print('max of pixeladv is',np.max(pixelsadv),'min of pixeladv is',np.min(pixelsadv))\n",
        "            # print('max of pixelsorig is',np.max(pixelsorig),'min of pixelsorig is',np.min(pixelsorig))\n",
        "            # #plt.axis('off')\n",
        "           \n",
        "\n",
        "            index = range(5)\n",
        "            pixelsorig = X.cpu().numpy()\n",
        "            pixelsadv = X_.cpu().numpy()\n",
        "            error = (pixelsorig-pixelsadv)\n",
        "            error = error - np.min(error)\n",
        "            error = error/np.max(error)\n",
        "            \n",
        "            #print('Showing difference after Wasserstein attack')\n",
        "            # difX0 = np.abs(X_[0].cpu().detach().numpy() - X[0].cpu().detach().numpy())\n",
        "            # print('max of dif is',np.max(difX0),'summ of X_[0] is',np.sum(X_[0].cpu().detach().numpy()),\n",
        "            #       'sum of X[0] is',np.sum(X[0].cpu().detach().numpy()))\n",
        "            # difX0 = difX0/(np.max(difX0)+0.0001)\n",
        "            # print('max of dif is',np.max(difX0))\n",
        "\n",
        "            # difX1 = np.abs(X_[1].cpu().detach().numpy() - X[1].cpu().detach().numpy())\n",
        "            # print('max of dif is',np.max(difX1),'max of X_[1] is',np.sum(X_[1].cpu().detach().numpy()),\n",
        "            #       'max of X[1] is',np.sum(X[1].cpu().detach().numpy()))\n",
        "            # difX1 = difX1/(np.max(difX1)+0.0001)\n",
        "            #print_cifar(difX)\n",
        "            err = (net(normalize(X_)).max(1)[1] != y)\n",
        "            predicted_class = net(normalize(X_)).max(1)[1]\n",
        "            flag = True\n",
        "            # for i in index:\n",
        "            #   # print('pred is..',predicted_class[i],'err',err[i])\n",
        "            #   if pixelsorig.shape[1]==3:\n",
        "            #     cv2.imwrite(os.path.join(path, 'orig_'+str(i)+'.jpg'),(255*pixelsorig[i].transpose(1,2,0)).astype(int))\n",
        "            #     if (err[i] == True):\n",
        "            #       cv2.imwrite(os.path.join(path, 'attack_'+str(i)+'.jpg'),(255*pixelsadv[i].transpose(1,2,0)).astype(int))\n",
        "            #       cv2.imwrite(os.path.join(path, 'error_'+str(i)+'.jpg'),(255*error[i].transpose(1,2,0)).astype(int))\n",
        "            #   if pixelsorig.shape[1]==1:\n",
        "            #     if t < 3:\n",
        "            #       cv2.imwrite(os.path.join(path, 'orig_'+str(i)+'_class_'+str(targets[i])+'.jpg'),(255*pixelsorig[i][0]).astype(int))\n",
        "            #       if (err[i] == True):\n",
        "            #         cv2.imwrite(os.path.join(path, 'attack_'+str(i)+'_class_'+str(targets[i])+'.jpg'),(255*pixelsadv[i][0]).astype(int))\n",
        "            #         cv2.imwrite(os.path.join(path, 'error_'+str(i)+'_class_'+str(targets[i])+'.jpg'),(255*error[i][0]).astype(int))\n",
        "            # #cv2.imwrite(os.path.join(path, 'OT_'+str(i)+'.jpg'),(255*OTpixels[0]).astype(int))\n",
        "            err_rate = err.sum().item()\n",
        "             \n",
        "            #print('diff = ......', torch.max(torch.abs(X_ - X)) )\n",
        "            if err_rate > err_best.sum().item():\n",
        "                X_best = X_.clone() \n",
        "                err_best = err\n",
        "            \n",
        "            t += 1\n",
        "            if err_rate == N or t == maxiters: \n",
        "                break\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    return X_best, y,err_best"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_CxMgF7aNga"
      },
      "source": [
        ""
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpKpHvNWl9_t"
      },
      "source": [
        "Formulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2trE3Ru1F0Ge",
        "outputId": "7f0a3ce7-4239-4c37-ca7a-fd0d85e577b6"
      },
      "source": [
        "p = 1\n",
        "kernel_size = 28\n",
        "C = wasserstein_cost(p=p, kernel_size= kernel_size, n =  kernel_size)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "alpha = 0.02\n",
        "norm = 'linfinity'\n",
        "model_state_dict = torch.load(\"/content/gdrive/MyDrive/Colab_Notebooks/MnistCNN\")\n",
        "model.load_state_dict(model_state_dict,strict=False)\n",
        "# model_state_dict = torch.load(\"/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/fashionmnist_dual_epoch_50_advacc_37.62_accuracy_82.09.pth\")\n",
        "# model.load_state_dict(model_state_dict['model'])\n",
        "start_epoch = 51\n",
        "checkpoint_dir = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints'\n",
        "checkpoint_file = '{}/fashionmnist_dual_epoch_{}_advacc_{}_accuracy_{}.pth'.format(checkpoint_dir,'{}','{}','{}')\n",
        "for pr in model.parameters(): \n",
        "    pr.requires_grad = True\n",
        "def trainfashion(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    nominal_correct = 0\n",
        "    total_epsilon = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        targets_attack = targets\n",
        "        inputs_pgd,y, _ = attack(torch.clamp(unnormalize(inputs),min=0), \n",
        "                                 targets_attack, model,  C, total,batch_idx,targets,\n",
        "                                 p= p, alpha=alpha , norm=norm ,\n",
        "                                 maxiters= 20 ,thold = 10 , normalize=normalize ,\n",
        "                                 gamma = .5 ,\n",
        "                                 kernel_size= 1024 , delta = 0.003 , \n",
        "                                 theeta = 100 , tau = .01 , \n",
        "                                 eta = .001 )\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(normalize(inputs_pgd))\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad(): \n",
        "            outputs_nominal = model(inputs)\n",
        "            _, predicted_nominal = outputs_nominal.max(1)\n",
        "            nominal_correct += predicted_nominal.eq(targets).sum().item()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "           \n",
        "            \n",
        "        print(batch_idx, len(trainloader), 'Loss: %.3f | Adv Acc: %.3f%% (%d/%d) | Acc: %.3f%% (%d/%d) '\n",
        "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total, \n",
        "                100.*nominal_correct/total, nominal_correct, total))\n",
        "        # if batch_idx == 0:\n",
        "        #   break\n",
        "   \n",
        "    advacc = np.round(100.*correct/total,2)\n",
        "    acc = np.round(100.*nominal_correct/total,2)\n",
        "    state = {\n",
        "        'model': model.state_dict(),\n",
        "        'acc': acc,\n",
        "        'advacc': advacc,\n",
        "        'epoch': epoch,\n",
        "    }\n",
        "    torch.save(state, checkpoint_file.format(epoch,advacc,acc))\n",
        "    # import shutil \n",
        "    # shutil.copy(checkpoint_file.format(epoch,advacc,acc), '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/')\n",
        "\n",
        "\n",
        "\n",
        "# model_state_dict = torch.load(\"/content/gdrive/MyDrive/Colab_Notebooks/MnistadvCNN\")\n",
        "# model.load_state_dict(model_state_dict)\n",
        "\n",
        "def testfashionmnist():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "           \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            \n",
        "    acc = 100.*correct/total\n",
        "    print('Accuracy = ', acc )\n",
        "\n",
        "def test_attackfashionmnist(): \n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batchOT = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        targets_attack = targets # should add or subtract for targeted attack\n",
        "        \n",
        "        N = inputs.size(0)\n",
        "        total += targets.size(0)\n",
        "        inputs_pgd,y,  _ = attack(torch.clamp(unnormalize(inputs),min=0), \n",
        "                                 targets_attack, model,  C, total,batch_idx,targets,\n",
        "                                 p= p, alpha=alpha , norm=norm ,\n",
        "                                 maxiters= 10 ,thold =10 , normalize=normalize ,\n",
        "                                 gamma = .5 ,\n",
        "                                 kernel_size= 784 , delta = 0.003 , \n",
        "                                 theeta = 100 , tau =.01 , eta = .001)\n",
        "                                #  eta = .25 )\n",
        "\n",
        "        outputs_pgd = model(normalize(inputs_pgd))\n",
        "        loss = criterion(outputs_pgd, y)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = outputs_pgd.max(1)\n",
        "        \n",
        "    \n",
        "        # pixelsorig = inputs.cpu().numpy()\n",
        "        # pixelsadv = inputs_pgd.cpu().numpy()\n",
        "        # error = (pixelsorig-pixelsadv)\n",
        "        # error = error - np.min(error)\n",
        "        # error = error/np.max(error)\n",
        "        # index = range(5)\n",
        "        # for i in index:\n",
        "            # cv2.imwrite(os.path.join(path, 'orig_'+str(i)+'.jpg'),(255*pixelsorig[i][0]).astype(int))\n",
        "            # cv2.imwrite(os.path.join(path, 'attack_'+str(i)+'.jpg'),(255*pixelsadv[i][0]).astype(int))\n",
        "            # cv2.imwrite(os.path.join(path, 'error_'+str(i)+'.jpg'),(255*error[i][0]).astype(int))\n",
        "\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        print('Batch ' , batch_idx , 'Loss = ' , test_loss/(batch_idx+1) , 'Accuracy = ' , 100.*correct/total  )\n",
        "        # print('original labels:predicted labels',targets,predicted)\n",
        "        if batch_idx==20:\n",
        "          break\n",
        "\n",
        "        acc = 100.*correct/total\n",
        "#         if batch_idx > 0:\n",
        "#           break\n",
        "    print('final accuracy = ' , 100.*correct/total)\n",
        "\n",
        "#print('==> Evaluating model..')\n",
        "\n",
        "# for epoch in range(start_epoch, start_epoch+30):\n",
        "#     print('traaining start......')\n",
        "#     test_attackfashionmnist()\n",
        "#     testfashionmnist()\n",
        "#     trainfashion(epoch)\n",
        "#     testmnist()\n",
        "# # print('==> Attacking model..')\n",
        "# test_attackfashionmnist()\n",
        "\n",
        "# model_state_dict  = torch.load(\"/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/fashionmnist_dual_epoch_57_advacc_38.43_accuracy_82.19.pth\")\n",
        "# net.load_state_dict(model_state_dict['model'])\n",
        "net = net.to(device)\n",
        "# testfashionmnist()\n",
        "\n",
        "\n",
        "# model_state_dict = torch.load(\"/content/gdrive/MyDrive/Colab_Notebooks/MnistCNN\")\n",
        "# net.load_state_dict(model_state_dict)\n",
        "net = net.to(device)\n",
        "# testfashionmnist()\n",
        "!zip -r /content/gdrive/MyDrive/Colab_Notebooks/Images/fashionMNIST.zip /content/gdrive/MyDrive/Colab_Notebooks/Images/fashionMNIST    "
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p is  1\n",
            "  adding: content/gdrive/MyDrive/Colab_Notebooks/Images/fashionMNIST/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOr3jgzOnBIB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAPjbUFKnBEq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBWiyd52mXCH"
      },
      "source": [
        " Gradient Sign attack which calls barycentre_attack\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2obYfFIcVY2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70403f35-a86f-48bd-eabb-85996e7b5c64"
      },
      "source": [
        "# ImageNet = torchvision.datasets.ImageNet(download=False, train=False, root=\".\").train_data.float()\n",
        "\n",
        "# data_transform = transforms.Compose([\n",
        "#     transforms.Resize(256),\n",
        "#     transforms.CenterCrop(224),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "# ])\n",
        "\n",
        "# trainloader = DataLoader(torchvision.datasets.ImageNet(download=False, root=\".\", transform=data_transform, train=True),\n",
        "#                           batch_size=1, shuffle=True)\n",
        "# testset = torchvision.datasets.ImageNet(root=\".\", train=False, download= True , transform=data_transform)\n",
        "# testloader = torch.utils.data.DataLoader(testset, batch_size= 4, shuffle= False )\n",
        "\n",
        "\n",
        "def testimagenet():\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "           \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            \n",
        "    acc = 100.*correct/total\n",
        "    print('Accuracy = ', acc )\n",
        "\n",
        "def test_attacktestimagenet(): \n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batchOT = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        targets_attack = targets # should add or subtract for targeted attack\n",
        "        \n",
        "        N = inputs.size(0)\n",
        "        total += targets.size(0)\n",
        "        inputs_pgd,y,  _ = attack(torch.clamp(unnormalize(inputs),min=0), \n",
        "                                 targets_attack, model,  C, total,batch_idx,targets,\n",
        "                                 p= p, alpha=alpha , norm=norm ,\n",
        "                                 maxiters= 1 ,thold =10 , normalize=normalize ,\n",
        "                                 gamma = .5 ,\n",
        "                                 kernel_size= 224*224 , delta = 0.003 , \n",
        "                                 theeta = 100 , tau =.01 , eta = .001)\n",
        "                                #  eta = .25 )\n",
        "\n",
        "        outputs_pgd = model(normalize(inputs_pgd))\n",
        "        loss = criterion(outputs_pgd, y)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = outputs_pgd.max(1)\n",
        "        \n",
        "    \n",
        "        # pixelsorig = inputs.cpu().numpy()\n",
        "        # pixelsadv = inputs_pgd.cpu().numpy()\n",
        "        # error = (pixelsorig-pixelsadv)\n",
        "        # error = error - np.min(error)\n",
        "        # error = error/np.max(error)\n",
        "        # index = range(5)\n",
        "        # for i in index:\n",
        "            # cv2.imwrite(os.path.join(path, 'orig_'+str(i)+'.jpg'),(255*pixelsorig[i][0]).astype(int))\n",
        "            # cv2.imwrite(os.path.join(path, 'attack_'+str(i)+'.jpg'),(255*pixelsadv[i][0]).astype(int))\n",
        "            # cv2.imwrite(os.path.join(path, 'error_'+str(i)+'.jpg'),(255*error[i][0]).astype(int))\n",
        "\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        print('Batch ' , batch_idx , 'Loss = ' , test_loss/(batch_idx+1) , 'Accuracy = ' , 100.*correct/total  )\n",
        "        # print('original labels:predicted labels',targets,predicted)\n",
        "        if batch_idx==0:\n",
        "          break\n",
        "\n",
        "        acc = 100.*correct/total\n",
        "#         if batch_idx > 0:\n",
        "#           break\n",
        "    print('final accuracy = ' , 100.*correct/total)\n",
        "\n",
        "#print('==> Evaluating model..')\n",
        "\n",
        "# for epoch in range(start_epoch, start_epoch+30):\n",
        "#     print('traaining start......')\n",
        "#     test_attackfashionmnist()\n",
        "#     testfashionmnist()\n",
        "#     trainfashion(epoch)\n",
        "#     testmnist()\n",
        "# # print('==> Attacking model..')\n",
        "# test_attackfashionmnist()\n",
        "\n",
        "# net = models.resnet18(pretrained=True)\n",
        "# net = net.to(device)\n",
        "# testfashionmnist()\n",
        "\n",
        "\n",
        "\n",
        "# testfashionmnist()\n",
        "!zip -r /content/gdrive/MyDrive/Colab_Notebooks/Images/fashionMNIST.zip /content/gdrive/MyDrive/Colab_Notebooks/Images/fashionMNIST    "
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: content/gdrive/MyDrive/Colab_Notebooks/Images/fashionMNIST/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVHnSyXLlj0D"
      },
      "source": [
        ""
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIJXVck-lj0G"
      },
      "source": [
        " Gradient Sign attack which calls barycentre_attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTSi0dnslj0H"
      },
      "source": [
        ""
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_ww4IuSwiT5",
        "outputId": "d47c53af-798d-4c43-a14d-8f1dc5b03339"
      },
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.RandomAffine(0,translate=(0,0)),                            \n",
        "    transforms.ToTensor(), ])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/dataset/data/', train=True, download=  True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True, num_workers=2)   # MNIST\n",
        "\n",
        "dig = 5 #The digit to attack\n",
        "testset = torchvision.datasets.MNIST(root='/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/dataset/data/', train=False, download= True , transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size= 200, shuffle= False )\n",
        "\n",
        "\n",
        "print('==> Building model..')\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "#uncomment for mnist\n",
        "\n",
        "net = nn.Sequential(\n",
        "        nn.Conv2d(1, 16, 4, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 32, 4, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(32*7*7,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 10)\n",
        "    )\n",
        "\n",
        "\n",
        "netattack=net"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "==> Building model..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0jdPFqXm283"
      },
      "source": [
        "Test on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTmLK9EeK-e"
      },
      "source": [
        ""
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUzyrWEtm8aZ"
      },
      "source": [
        "\n",
        "#uncomment for mnist\n",
        "\n",
        "# if device == 'cuda':\n",
        "#     net = torch.nn.DataParallel(net)\n",
        "#     cudnn.benchmark = True  \n",
        "net = net.to(device)\n",
        "netattack = netattack.to(device)\n",
        "checkpoint_dir = '/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/checkpoints'\n",
        "checkpoint_file = '{}/cifar_dual_epoch_{}_advacc_{}_acc_{}.pth'.format(checkpoint_dir,'{}','{}','{}')\n",
        "\n",
        "alpha = 0.02\n",
        "norm = 'linfinity'\n",
        "\n",
        "# for mnist\n",
        "#model_name = '/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/checkpoints/mnist_dual_epoch_39_advacc_92.86_acc_99.8_OT_3.643.pth'\n",
        "#for cifar\n",
        "#model_name = '/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/checkpoints/cifar_vanilla.pth'\n",
        "# model_name = '/content/gdrive/MyDrive/Colab_Notebooks/projected_sinkhorn-wong/checkpoints/mnist_adv_training_wong.pth'\n",
        "# model_name = '/content/gdrive/MyDrive/Colab_Notebooks/projected_sinkhorn-wong/checkpoints/mnist_adv_training_ours.pth'\n",
        "\n",
        "#https://github.com/akamaster/pytorch_resnet_cifar10\n",
        "\n",
        "# model_name = '/content/gdrive/MyDrive/Colab_Notebooks/resnet56-4bfd9763.th'\n",
        "# model_name = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/cifar_dual_epoch_5_advacc_58.57_acc_99.98_OT_0.004999999888241291.pth'\n",
        "# model_name = '/content/gdrive/MyDrive/Colab_Notebooks/projected_sinkhorn-wong/checkpoints/cifar_adv_training_wong.pth'\n",
        "model_name = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/mnist_vanilla.pth'\n",
        "\n",
        "# model_name = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/mnist_dual_epoch_59_advacc_88.24_acc_98.31_OT_3.917.pth'\n",
        "# model_name = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/mnist_linf_robust.pth'\n",
        "#model_name = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/cifar_dual_epoch_0_advacc_58.96_acc_94.77_OT_0.02500000037252903.pth'\n",
        "# model_name  = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/mnist_dual_epoch_5_advacc_83.96_acc_99.69_OT_3.643.pth'\n",
        "# model_name  = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/mnist_dual_epoch_9_advacc_87.21_acc_99.71_OT_3.643.pth'\n",
        "# model_name  = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/mnist_dual_epoch_15_advacc_89.56_acc_99.74_OT_3.643.pth'\n",
        "\n",
        "\n",
        "# model_name  = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/cifar_dual_epoch_6_advacc_6.05_acc_99.97_OT_0.00800000037997961.pth'\n",
        "\n",
        "# model_name  = '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/mnist_dual_epoch_39_advacc_85.66_acc_98.08_OT_3.917.pth'\n",
        "\n",
        "\n",
        "\n",
        "binarize = False\n",
        "\n",
        "# print('==> loading model {}'.format(model_name))\n",
        "\n",
        "#uncomment it for mnist vanilla\n",
        "# d = torch.load(model_name, map_location = 'cpu')\n",
        "\n",
        "# # comment this for mnist\n",
        "# d = torch.load(model_name)\n",
        "# if 'state_dict' in d: \n",
        "#     net.load_state_dict(d['state_dict'][0])    \n",
        "# elif 'robust' in model_name: \n",
        "#     net.load_state_dict(d)\n",
        "# else: \n",
        "#     net.load_state_dict(d['net'])\n",
        "\n",
        "\n",
        "# uncomment for adversarial model of wong\n",
        "# checkpoint = torch.load(model_name)\n",
        "# for key in list(checkpoint['net'].keys()):\n",
        "#   new_key = key[7:]\n",
        "#   checkpoint['net'][new_key] = checkpoint['net'].pop(key)\n",
        "# net.load_state_dict(checkpoint['net'],strict=False)\n",
        "# net = net.to(device)\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def testmnist():\n",
        "    netattack.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            if binarize:\n",
        "                inputs = (inputs >= 0.5).float()\n",
        "            outputs = netattack(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100.*correct/total\n",
        "    print('Accuracy = ', acc )\n",
        "\n",
        "\n",
        "# model_name = '/content/gdrive/MyDrive/Colab_Notebooks/projected_sinkhorn-wong/checkpoints/mnist_adv_training_ours.pth'\n",
        "# checkpoint = torch.load(model_name)\n",
        "# for key in list(checkpoint['net'].keys()):\n",
        "#   new_key = key[7:]\n",
        "#   checkpoint['net'][new_key] = checkpoint['net'].pop(key)\n",
        "# net.load_state_dict(checkpoint['net'],strict=False)\n",
        "# net = net.to(device)\n",
        "# testmnist()\n",
        "\n",
        "# model_name = '/content/gdrive/MyDrive/Colab_Notebooks/projected_sinkhorn-wong/checkpoints/mnist_adv_training_wong.pth'\n",
        "# checkpoint = torch.load(model_name)\n",
        "# for key in list(checkpoint['net'].keys()):\n",
        "#   new_key = key[7:]\n",
        "#   checkpoint['net'][new_key] = checkpoint['net'].pop(key)\n",
        "# net.load_state_dict(checkpoint['net'],strict=False)\n",
        "# net = net.to(device)\n",
        "# testmnist()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PePZ_-KF5Cdk"
      },
      "source": [
        ""
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_OFGI3cVD6P"
      },
      "source": [
        ""
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UOUQFYIoi-g",
        "outputId": "fad76ee6-8893-48ba-b7b1-bdd588eee931"
      },
      "source": [
        "normalize = lambda x: x #comment for cifar\n",
        "p = 1\n",
        "kernel_size = 28\n",
        "C = wasserstein_cost(p=p, kernel_size= kernel_size, n =  kernel_size)\n",
        "\n",
        "def test_attackmnist(): \n",
        "    netattack.eval()\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batchOT = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        targets_attack = targets # should add or subtract for targeted attack\n",
        "        if binarize: \n",
        "            inputs = (inputs >= 0.5).float()\n",
        "        N = inputs.size(0)\n",
        "        total += targets.size(0)\n",
        "        inputs_pgd,y,  _ = attack(torch.clamp((inputs),min=0), \n",
        "                                 targets_attack, netattack,  C, total,batch_idx,targets,\n",
        "                                 p= p, alpha=alpha , norm=norm ,\n",
        "                                 maxiters= 10 ,thold =10 , normalize=normalize ,\n",
        "                                 gamma = .5 ,\n",
        "                                 kernel_size= 784 , delta = 0.003 , \n",
        "                                 theeta = 100 , tau =.01 , eta = .001)\n",
        "                                #  eta = .25 )\n",
        "\n",
        "        outputs_pgd = net(inputs_pgd)\n",
        "        loss = criterion(outputs_pgd, y)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = outputs_pgd.max(1)\n",
        "        \n",
        "    \n",
        "        # pixelsorig = inputs.cpu().numpy()\n",
        "        # pixelsadv = inputs_pgd.cpu().numpy()\n",
        "        # error = (pixelsorig-pixelsadv)\n",
        "        # error = error - np.min(error)\n",
        "        # error = error/np.max(error)\n",
        "        # index = range(5)\n",
        "        # for i in index:\n",
        "            # cv2.imwrite(os.path.join(path, 'orig_'+str(i)+'.jpg'),(255*pixelsorig[i][0]).astype(int))\n",
        "            # cv2.imwrite(os.path.join(path, 'attack_'+str(i)+'.jpg'),(255*pixelsadv[i][0]).astype(int))\n",
        "            # cv2.imwrite(os.path.join(path, 'error_'+str(i)+'.jpg'),(255*error[i][0]).astype(int))\n",
        "\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        print('Batch ' , batch_idx , 'Loss = ' , test_loss/(batch_idx+1) , 'Accuracy = ' , 100.*correct/total  )\n",
        "        # print('original labels:predicted labels',targets,predicted)\n",
        "        if batch_idx==0:\n",
        "          break\n",
        "\n",
        "        acc = 100.*correct/total\n",
        "#         if batch_idx > 0:\n",
        "#           break\n",
        "    print('final accuracy = ' , 100.*correct/total)\n",
        "\n",
        "#print('==> Evaluating model..')\n",
        "\n",
        "# # print('==> Attacking model..')\n",
        "start = time.time()\n",
        "test_attackmnist()\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end - start}\")\n",
        "\n",
        "# !zip -r /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST.zip /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p is  1\n",
            "Batch  0 Loss =  2.307671546936035 Accuracy =  0.0\n",
            "final accuracy =  0.0\n",
            "Runtime of the program is 3.834124803543091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkvApkmXDgej"
      },
      "source": [
        "# !zip -r /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST.zip /content/gdrive/MyDrive/Colab_Notebooks/Images/MNIST"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVw_6UuwDYzG"
      },
      "source": [
        "# Training\n",
        "start_epoch = 0 # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "# optimizer = optim.SGD(net.parameters(), lr=.5, momentum=0.9)\n",
        "\n",
        "# scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "for pr in net.parameters(): \n",
        "    pr.requires_grad = True\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    nominal_correct = 0\n",
        "    total_epsilon = 0\n",
        "    total = 0\n",
        "    batchOT = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        targets_attack = targets\n",
        "        # inputs_pgd,y, OT, _ = attack(torch.clamp((inputs),min=0), \n",
        "        #                          targets_attack, net,  C, total,batch_idx,targets,\n",
        "        #                          p= p, alpha=alpha , norm=norm ,\n",
        "        #                          maxiters= 20 ,thold = 10 , normalize=normalize ,\n",
        "        #                          gamma = .5 ,\n",
        "        #                          kernel_size= 1024 , delta = 0.003 , \n",
        "        #                          theeta = 100 , tau = .01 , \n",
        "        #                          eta = .001 )\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad(): \n",
        "            outputs_nominal = net(inputs)\n",
        "            _, predicted_nominal = outputs_nominal.max(1)\n",
        "            nominal_correct += predicted_nominal.eq(targets).sum().item()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "           \n",
        "            \n",
        "        print(batch_idx, len(trainloader), 'Loss: %.3f | Adv Acc: %.3f%% (%d/%d) | Acc: %.3f%% (%d/%d) '\n",
        "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total, \n",
        "                100.*nominal_correct/total, nominal_correct, total))\n",
        "        # if batch_idx == 2:\n",
        "        #   break\n",
        "   \n",
        "    advacc = np.round(100.*correct/total,2)\n",
        "    acc = np.round(100.*nominal_correct/total,2)\n",
        "    state = {\n",
        "        'net': net.state_dict(),\n",
        "        'acc': acc,\n",
        "        'advacc': advacc,\n",
        "        'epoch': epoch,\n",
        "    }\n",
        "    torch.save(state, checkpoint_file.format(epoch,advacc,acc))\n",
        "    import shutil \n",
        "    shutil.copy(checkpoint_file.format(epoch,advacc,acc), '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/')\n",
        "\n",
        "def test(epoch):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    nominal_correct = 0\n",
        "    total = 0\n",
        "    total_epsilon = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        inputs_pgd, _, epsilons = attack(torch.clamp((inputs),min=0), \n",
        "                                 targets, net,  C, total,\n",
        "                                 p= p, alpha=alpha , norm=norm ,\n",
        "                                 maxiters= 2 ,thold = 30 , normalize=normalize ,\n",
        "                                 gamma = 2000 ,\n",
        "                                 kernel_size= 1024 , delta = 0.003 , \n",
        "                                 theeta = 100 , tau = 5 ,\n",
        "                                 eta = .5 )\n",
        "        with torch.no_grad():\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            outputs_nominal = net(inputs)\n",
        "            _, predicted_nominal = outputs_nominal.max(1)\n",
        "            nominal_correct += predicted_nominal.eq(targets).sum().item()\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            total_epsilon += epsilons.sum().item()\n",
        "            \n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d) | Acc: %.3f%% (%d/%d) | Eps: %.3f%%'\n",
        "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total, \n",
        "                100.*nominal_correct/total, nominal_correct, total, total_epsilon/total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    # acc = 100.*correct/total\n",
        "    # avg_epsilon = total_epsilon/total\n",
        "    \n",
        "    state = {\n",
        "        'net': net.state_dict(),\n",
        "        'acc': acc,\n",
        "        'eps': avg_epsilon,\n",
        "        'epoch': epoch,\n",
        "    }\n",
        "    if not os.path.isdir(checkpoint_dir):\n",
        "        os.mkdir(checkpoint_dir)\n",
        "    torch.save(state, checkpoint_file.format(epoch))\n",
        "\n",
        "\n",
        "# for epoch in range(start_epoch, start_epoch+):\n",
        "#     print('traaining start......')\n",
        "#     train(epoch)\n",
        "#     testmnist()\n",
        "#     #test(epoch)\n",
        "    #acc = 100.*correct/total\n",
        "    \n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTsvVQgqzVeq"
      },
      "source": [
        ""
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU4xPQWH5iZ6"
      },
      "source": [
        ""
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEz-Fazl0B7e"
      },
      "source": [
        ""
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXYZNDHBDYzI"
      },
      "source": [
        "# import os\n",
        "# import argparse\n",
        "# import sys\n",
        "# #sys.path.append('drive/MyDrive/projected_sinkhorn/')\n",
        "# # sys.path.append('/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/models')\n",
        "# from models.resnet import *\n",
        "\n",
        "\n",
        "\n",
        "# alpha = 0.02\n",
        "# norm = 'linfinity'\n",
        "\n",
        "# #model_name = '/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/checkpoints/cifar_dual_epoch_0_advacc_61.24_acc_99.91_OT_0.004999999888241291.pth'\n",
        "\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# best_acc = 0  # best test accuracy\n",
        "\n",
        "# print('==> Preparing data..')\n",
        "# transform_train = transforms.Compose([\n",
        "#     transforms.RandomCrop(32, padding=4),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "#     # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "# ])\n",
        "\n",
        "# transform_test = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "# ])\n",
        "# mu = torch.Tensor((0.4914, 0.4822, 0.4465)).unsqueeze(-1).unsqueeze(-1).to(device)\n",
        "# std = torch.Tensor((0.2471, 0.2435, 0.2616)).unsqueeze(-1).unsqueeze(-1).to(device)\n",
        "# unnormalize = lambda x: x*std + mu\n",
        "# normalize = lambda x: (x-mu)/std\n",
        "\n",
        "# def cycle(iterable):\n",
        "#     while True:\n",
        "#         for x in iterable:\n",
        "#             yield x\n",
        "\n",
        "# # Return only images of certain class (eg. aeroplanes = class 0)\n",
        "# def get_same_index(target, label):\n",
        "#     label_indices = []\n",
        "#     for i in range(len(target)):\n",
        "#         if target[i] == label:\n",
        "#             label_indices.append(i)\n",
        "#     return label_indices\n",
        "\n",
        "\n",
        "\n",
        "# trainset = torchvision.datasets.CIFAR10(root='./drive/MyDrive/projected_sinkhorn/dataset/', train=True, download=True, transform=transform_train)\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True ) #CIFAR\n",
        "\n",
        "# testset = torchvision.datasets.CIFAR10(root='./drive/MyDrive/projected_sinkhorn/dataset/', train=False, download=True, transform=transform_test)\n",
        "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# # label_class = 9 # birds\n",
        "\n",
        "# # train_indices = get_same_index( testset.targets, label_class)\n",
        "# # catset = torch.utils.data.Subset(testset, train_indices)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Model architecture is from pytorch-cifar submodule\n",
        "# print('==> Building model..')\n",
        "# net = resnet18(pretrained=False)\n",
        "# # net = net.to(device)\n",
        "# # if device == 'cuda':\n",
        "# #     net = torch.nn.DataParallel(net)\n",
        "# #     cudnn.benchmark = True\n",
        "\n",
        "# # # Load checkpoint.\n",
        "# # print('==> Resuming from checkpoint..')\n",
        "# # checkpoint = torch.load(model_name)\n",
        "\n",
        "# #comment this for loading our adv trained model\n",
        "# # for key in list(checkpoint['net'].keys()):\n",
        "# #   new_key = key[7:]\n",
        "# #   checkpoint['net'][new_key] = checkpoint['net'].pop(key)\n",
        "# # net.load_state_dict(checkpoint['net'])\n",
        "\n",
        "# # for key in list(checkpoint.keys()):\n",
        "# #   new_key = key[7:]\n",
        "# #   checkpoint[new_key] = checkpoint.pop(key)\n",
        "# # net.load_state_dict(checkpoint,strict=False) # if name has 'robust'\n",
        "# net = net.to(device)\n"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_lfrXqyEYom"
      },
      "source": [
        ""
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBPHnsx9Kfgz"
      },
      "source": [
        "\n",
        "# freeze parameters\n",
        "# for pr in net.parameters(): \n",
        "#     pr.requires_grad = True\n",
        "\n",
        "# for pr in net.layer4.parameters():\n",
        "#   pr.requires_grad = True\n",
        "\n",
        "# for pr in net.linear.parameters():\n",
        "#   pr.requires_grad = True\n",
        "\n",
        "# for pr in net.layer4.parameters():\n",
        "#   print(pr.requires_grad)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# testloader = torch.utils.data.DataLoader(testset, batch_size= 200 , shuffle= True )\n",
        "# def testcifar():\n",
        "#     net.eval()\n",
        "#     test_loss = 0\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     with torch.no_grad():\n",
        "#         for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "#             inputs, targets = inputs.to(device), targets.to(device)\n",
        "#             outputs = net(inputs)\n",
        "#             loss = criterion(outputs, targets)\n",
        "\n",
        "#             test_loss += loss.item()\n",
        "#             _, predicted = outputs.max(1)\n",
        "#             total += targets.size(0)\n",
        "#             correct += predicted.eq(targets).sum().item()\n",
        "#             # if batch_idx > 10:\n",
        "#             #   break\n",
        "\n",
        "#     acc = 100.*correct/total\n",
        "#     print('cifar test accuracy is',acc)\n",
        "\n",
        "\n",
        "\n",
        "# print('==> Evaluating model..')\n",
        "# # testcifar()\n",
        "# print('==> Attacking model..')\n"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAGF5FnJKblJ"
      },
      "source": [
        ""
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmJtZjaa6gl8"
      },
      "source": [
        "# p = 1\n",
        "# kernel_size = 32\n",
        "# C = wasserstein_cost(p=p, kernel_size= kernel_size, n = kernel_size )\n",
        "\n",
        "# def test_attackcifar(): \n",
        "#     net.eval()\n",
        "#     test_loss = 0\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     batchOT = 0\n",
        "\n",
        "#     for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        \n",
        "#         inputs, targets = inputs.to(device), targets.to(device)\n",
        "#         targets_attack = targets # should add or subtract for targeted attack\n",
        "#         N = inputs.size(0)\n",
        "#         start = timeit.timeit()\n",
        "#         total += targets.size(0)\n",
        "#         inputs_pgd,y, OT, _ = attack(torch.clamp(unnormalize(inputs),min=0), \n",
        "#                                  targets_attack, net,  C,total,batch_idx,targets,\n",
        "#                                         p= p, alpha=alpha , norm=norm ,\n",
        "#                                   maxiters= 10 ,thold = 10 , normalize=normalize ,\n",
        "#                                  gamma = .5 ,\n",
        "#                                  kernel_size= inputs.size(2) , delta = 0.003 , \n",
        "#                                  theeta = 100 , tau = .01 , \n",
        "#                                  eta = .001)\n",
        "                        \n",
        "#         outputs_pgd = net(normalize(inputs_pgd))\n",
        "#         loss = criterion(outputs_pgd, y)\n",
        "#         batchOT = batchOT + sum(OT)\n",
        "#         test_loss += loss.item()\n",
        "#         _, predicted = outputs_pgd.max(1)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         AvgOT = batchOT/total\n",
        "#         correct += predicted.eq(y).sum().item()\n",
        "#         #print('total is.........',total)\n",
        "#         print('Batch ' , batch_idx , 'Loss = ' , \n",
        "#               test_loss/(batch_idx+1) , 'Accuracy = ' , \n",
        "#               100.*correct/total, 'avg ot = ', AvgOT )\n",
        "#         end = timeit.timeit()\n",
        "#         # print('taargets:predicted',targets,predicted)\n",
        "#         if batch_idx == 2:\n",
        "#           break\n",
        "#         acc = 100.*correct/total\n",
        "#         AvgOT = batchOT/total\n",
        "        \n",
        "#     print('final acc = ' , 100.*correct/total, 'avg ot = ', AvgOT)\n",
        "    \n",
        "# # test_attackcifar()\n",
        "# # !zip -r /content/gdrive/MyDrive/Colab_Notebooks/Images/CIFAR.zip /content/gdrive/MyDrive/Colab_Notebooks/Images/CIFAR"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTmsfJbFs-H3"
      },
      "source": [
        "# !zip -r /content/gdrive/MyDrive/Colab_Notebooks/Images/CIFAR.zip /content/gdrive/MyDrive/Colab_Notebooks/Images/CIFAR"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orvd9gYTCtI9"
      },
      "source": [
        "# # Model\n",
        "# print('==> Building model..')\n",
        "# net = ResNet18()\n",
        "# net = net.to(device)\n",
        "# if device == 'cuda':\n",
        "#     net = torch.nn.DataParallel(net)\n",
        "#     cudnn.benchmark = True\n",
        "\n",
        "\n",
        "# def traincifar(epoch):\n",
        "#     print('\\nEpoch: %d' % epoch)\n",
        "#     net.train()\n",
        "#     train_loss = 0\n",
        "#     correct = 0\n",
        "#     nominal_correct = 0\n",
        "#     total_epsilon = 0\n",
        "#     total = 0\n",
        "#     batchOT = 0\n",
        "    \n",
        "#     for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "#         inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "#         target_attacks = targets\n",
        "#         # inputs_pgd,y, OT, _ = attack(torch.clamp(unnormalize(inputs),min=0), \n",
        "#         #                          target_attacks, net,  C, total,batch_idx,targets,\n",
        "#         #                          p= p, alpha=alpha , norm=norm ,\n",
        "#         #                          maxiters= 1 ,thold = 10 , normalize=normalize ,\n",
        "#         #                          gamma = .5 ,\n",
        "#         #                          kernel_size= 1024 , delta = 0.003 , \n",
        "#         #                          theeta = 100 , tau = .01 , \n",
        "#         #                          eta = 0.001 )\n",
        "        \n",
        "#         # print('Showing adv image at iter ',batch_idx)\n",
        "#         # pixelsadv = inputs_pgd[0].cpu().numpy()\n",
        "#         # print('max of adv',np.max(pixelsadv))\n",
        "#         # print_cifar(pixelsadv)\n",
        "#         # print('Showing original for inputs',batch_idx)\n",
        "#         # pixelsadv = inputs[0].cpu().numpy()\n",
        "#         # print('max of orig',np.max(pixelsadv))\n",
        "#         # print_cifar(pixelsadv)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         # outputs = net(normalize(inputs_pgd.detach()))\n",
        "#         outputs = net(normalize(inputs))\n",
        "#         loss = criterion(outputs, targets)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         with torch.no_grad(): \n",
        "#             outputs_nominal = net((inputs))\n",
        "#             _, predicted_nominal = outputs_nominal.max(1)\n",
        "#             nominal_correct += predicted_nominal.eq(targets).sum().item()\n",
        "\n",
        "#             train_loss += loss.item()\n",
        "#             _, predicted = outputs.max(1)\n",
        "#             total += targets.size(0)\n",
        "#             correct += predicted.eq(targets).sum().item()\n",
        "#             # batchOT = batchOT + torch.sum(OT)\n",
        "#             # AvgOT = batchOT/total\n",
        "\n",
        "#         print(batch_idx, len(trainloader), 'Loss: %.3f | Adv Acc: %.3f%% (%d/%d) | Acc: %.3f%% (%d/%d)'\n",
        "#             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total, \n",
        "#                 100.*nominal_correct/total, nominal_correct, total))\n",
        "#         # if batch_idx == 50:\n",
        "#         #   break\n",
        "#     # AvgOT = AvgOT.cpu().numpy()\n",
        "#     # AvgOT = np.round(AvgOT,3)\n",
        "#     advacc = np.round(100.*correct/total,2)\n",
        "#     print(advacc)\n",
        "#     acc = np.round(100.*nominal_correct/total,2)\n",
        "#     state = {\n",
        "#         'net': net.state_dict(),\n",
        "#         'acc': acc,\n",
        "#         'advacc': advacc,\n",
        "#         # 'AvgOT': AvgOT,\n",
        "#         'epoch': epoch,\n",
        "#     }\n",
        "#     torch.save(state, checkpoint_file.format(epoch,advacc,acc))\n",
        "#     import shutil \n",
        "#     shutil.copy(checkpoint_file.format(epoch,advacc,acc), '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/')\n",
        "\n",
        "# def test_attack(): \n",
        "#     net.eval()\n",
        "#     test_loss = 0\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     all_epsilons = []\n",
        "\n",
        "#     for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "#         inputs, targets = inputs.to(device), targets.to(device)\n",
        "#         inputs_pgd,y, OT, _ = attack(torch.clamp(unnormalize(inputs),min=0), \n",
        "#                                  target_attacks, net,  C, total,batch_idx,targets,\n",
        "#                                  p= p, alpha=alpha , norm=norm ,\n",
        "#                                  maxiters= 2 ,thold = 30 , normalize=normalize ,\n",
        "#                                  gamma = 2000 ,\n",
        "#                                  kernel_size= 1024 , delta = 0.003 , \n",
        "#                                  theeta = 100 , tau = 5 , \n",
        "#                                  eta = 0.5 )\n",
        "\n",
        "#         outputs_pgd = net(normalize(inputs_pgd))\n",
        "#         loss = criterion(outputs_pgd, targets)\n",
        "\n",
        "#         test_loss += loss.item()\n",
        "#         _, predicted = outputs_pgd.max(1)\n",
        "#         total += targets.size(0)\n",
        "#         correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "#         # epsilons[predicted == targets] = -1\n",
        "#         # all_epsilons.append(epsilons)\n",
        "\n",
        "#         # print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d) | Avg epsilon: %.3f'\n",
        "#         #     % (test_loss/(batch_idx+1), 100.*correct/total, correct, total, torch.cat(all_epsilons).float().mean().item()))\n",
        "#         # print('\\n')\n",
        "#         print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d) '\n",
        "#             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "#         print('\\n')\n",
        "        \n",
        "\n",
        "#     acc = 100.*correct/total\n",
        "#     #all_epsilons = torch.cat(all_epsilons) \n",
        "\n",
        "\n",
        "# #test_attack()\n",
        "# for epoch in range(start_epoch, start_epoch+10):\n",
        "#     traincifar(epoch)\n",
        "#     scheduler.step()\n",
        "#     test_attackcifar()\n",
        "\n",
        "# # testloader = torch.utils.data.DataLoader(testset, batch_size= 50 , shuffle= True )\n",
        "# # testcifar()\n",
        "# # #acc = 100.*correct/total\n",
        "# # print('Saving..')\n",
        "# # state = {\n",
        "# #     'net': net.state_dict(),\n",
        "# # }\n",
        "# # # if not os.path.isdir(checkpoint_dir):\n",
        "# # #     os.mkdir(checkpoint_dir)\n",
        "# # torch.save(state, '/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/cifar10_dual.pth')\n"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liZGtttEmUGi"
      },
      "source": [
        "\n"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352,
          "referenced_widgets": [
            "fa1638c7131a45acbd4ce0510ce1327b",
            "b03f50a264654b999e72909a8bd6b540",
            "98fecd2b0de24329ae200fdb4c3d30bf",
            "408d80e47b554302a8a6ca75f6b41709",
            "21454eb223754465a2b36578129b53b0",
            "18e612af3a5040f792cac4fd842136b4",
            "af6dd7ec24194c8ca6fa756360854a56",
            "89e985c18e8a4a60b95311a6c3e5538e"
          ]
        },
        "id": "h1S3biRdDYzI",
        "outputId": "768e30e6-65ea-45b2-93ff-7d8c3fd1f630"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    #  std=[0.229, 0.224, 0.225]),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    #  std=[0.229, 0.224, 0.225]),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./drive/MyDrive/projected_sinkhorn/dataset/', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=1, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./drive/MyDrive/projected_sinkhorn/dataset/', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=200, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# net = resnet56_custom()\n",
        "# checkpoint = torch.load(model_name)\n",
        "# for key in list(checkpoint['state_dict'].keys()):\n",
        "#   new_key = key[7:]\n",
        "#   checkpoint['state_dict'][new_key] = checkpoint['state_dict'].pop(key)\n",
        "# net.load_state_dict(checkpoint['state_dict'],strict=False)\n",
        "# mu = torch.Tensor((0.485, 0.456, 0.406)).unsqueeze(-1).unsqueeze(-1).to(device)\n",
        "# std = torch.Tensor((0.229, 0.224, 0.225)).unsqueeze(-1).unsqueeze(-1).to(device)\n",
        "\n",
        "net = ResNet18()\n",
        "checkpoint = torch.load(model_name)\n",
        "for key in list(checkpoint['net'].keys()):\n",
        "  new_key = key[7:]\n",
        "  checkpoint['net'][new_key] = checkpoint['net'].pop(key)\n",
        "net.load_state_dict(checkpoint['net'],strict=False)\n",
        "mu = torch.Tensor((0.4914, 0.4822, 0.4465)).unsqueeze(-1).unsqueeze(-1).to(device)\n",
        "std = torch.Tensor((0.2023, 0.1994, 0.2010)).unsqueeze(-1).unsqueeze(-1).to(device)\n",
        "\n",
        "net=net.to(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr=.00001, weight_decay=.0005)\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "net = net.to(device)\n",
        "\n",
        "\n",
        "for pr in net.parameters(): \n",
        "    pr.requires_grad = False\n",
        "\n",
        "\n",
        "checkpoint_dir = '/content/gdrive/MyDrive/Colab_Notebooks/drive/MyDrive/projected_sinkhorn/checkpoints'\n",
        "checkpoint_file = '{}/cifar_dual_epoch_{}_testacc_{}_attackacc_{}.pth'.format(checkpoint_dir,'{}','{}','{}')\n",
        "\n",
        "\n",
        "unnormalize = lambda x: x*std + mu\n",
        "normalize = lambda x: (x-mu)/std\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "p = 1\n",
        "kernel_size = 32\n",
        "C = wasserstein_cost(p=p, kernel_size= kernel_size, n = kernel_size )\n",
        "testacc=0 \n",
        "attackacc=0\n",
        "def test_attackcifar(): \n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batchOT = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        targets_attack = targets # should add or subtract for targeted attack\n",
        "        N = inputs.size(0)\n",
        "        total += targets.size(0)\n",
        "        inputs_pgd,y,  _ = attack(torch.clamp(unnormalize(inputs),min=0), \n",
        "                                 targets_attack, net,  C,total,batch_idx,targets,\n",
        "                                        p= p, alpha=alpha , norm=norm ,\n",
        "                                  maxiters= 50 ,thold = 10 , normalize=normalize ,\n",
        "                                 gamma = .5 ,\n",
        "                                 kernel_size= inputs.size(2) , delta = 0.003 , \n",
        "                                 theeta = 100 , tau = .01 , \n",
        "                                 eta = .001)\n",
        "                        \n",
        "        outputs_pgd = net(normalize(inputs_pgd))\n",
        "        loss = criterion(outputs_pgd, y)\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = outputs_pgd.max(1)\n",
        "        \n",
        "        correct += predicted.eq(y).sum().item()\n",
        "        #print('total is.........',total)\n",
        "        print('Batch ' , batch_idx , 'Loss = ' , \n",
        "              test_loss/(batch_idx+1) , 'Accuracy = ' , \n",
        "              100.*correct/total)\n",
        "        # print('taargets:predicted',targets,predicted)\n",
        "        # if batch_idx == 2:\n",
        "        #   break\n",
        "        attackacc = 100.*correct/total\n",
        "        \n",
        "    print('final acc = ' , 100.*correct/total)\n",
        "    return attackacc\n",
        "\n",
        "def testcifar():\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            # if batch_idx > 10:\n",
        "            #   break\n",
        "\n",
        "    testacc = 100.*correct/total\n",
        "    print('cifar test accuracy is',testacc)\n",
        "    return testacc\n",
        "\n",
        "\n",
        "print('==> Evaluating model..')\n",
        "testcifar()\n",
        "print('==> Attacking model..')\n",
        "\n",
        "checkpoint = torch.load(model_name)\n",
        "for key in list(checkpoint['net'].keys()):\n",
        "  new_key = key[7:]\n",
        "  checkpoint['net'][new_key] = checkpoint['net'].pop(key)\n",
        "net.load_state_dict(checkpoint['net'],strict=False)\n",
        "\n",
        "testcifar()\n",
        "def traincifar(testacc,attackacc,epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    nominal_correct = 0\n",
        "    total_epsilon = 0\n",
        "    total = 0\n",
        "    batchOT = 0\n",
        "    \n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        target_attacks = targets\n",
        "        inputs_pgd,y, _ = attack(torch.clamp(unnormalize(inputs),min=0), \n",
        "                                 target_attacks, net,  C, total,batch_idx,targets,\n",
        "                                 p= p, alpha=alpha , norm=norm ,\n",
        "                                 maxiters= 5 ,thold = 10 , normalize=normalize ,\n",
        "                                 gamma = .5 ,\n",
        "                                 kernel_size= 1024 , delta = 0.003 , \n",
        "                                 theeta = 100 , tau = .01 , \n",
        "                                 eta = 0.001 )\n",
        "        \n",
        "        # print('Showing adv image at iter ',batch_idx)\n",
        "        # pixelsadv = inputs_pgd[0].cpu().numpy()\n",
        "        # print('max of adv',np.max(pixelsadv))\n",
        "        # print_cifar(pixelsadv)\n",
        "        # print('Showing original for inputs',batch_idx)\n",
        "        # pixelsadv = inputs[0].cpu().numpy()\n",
        "        # print('max of orig',np.max(pixelsadv))\n",
        "        # print_cifar(pixelsadv)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # outputs = net(normalize(inputs_pgd.detach()))\n",
        "        outputs = net(normalize(inputs_pgd))\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad(): \n",
        "            outputs_nominal = net(normalize(inputs))\n",
        "            _, predicted_nominal = outputs_nominal.max(1)\n",
        "            nominal_correct += predicted_nominal.eq(targets).sum().item()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            # batchOT = batchOT + torch.sum(OT)\n",
        "            # AvgOT = batchOT/total\n",
        "\n",
        "        print(batch_idx, len(trainloader), 'Loss: %.3f | Adv Acc: %.3f%% (%d/%d) | Acc: %.3f%% (%d/%d)'\n",
        "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total, \n",
        "                100.*nominal_correct/total, nominal_correct, total))\n",
        "        # if batch_idx == 50:\n",
        "        #   break\n",
        "    # AvgOT = AvgOT.cpu().numpy()\n",
        "    # AvgOT = np.round(AvgOT,3)\n",
        "   \n",
        "    acc = np.round(100.*nominal_correct/total,2)\n",
        "    state = {\n",
        "        'net': net.state_dict(),\n",
        "        'testacc': testacc,\n",
        "        'attackacc': attackacc,\n",
        "        # 'AvgOT': AvgOT,\n",
        "        'epoch': epoch,\n",
        "    }\n",
        "    torch.save(state, checkpoint_file.format(epoch,testacc,attackacc))\n",
        "    import shutil \n",
        "    shutil.copy(checkpoint_file.format(epoch,testacc,attackacc), '/content/gdrive/MyDrive/projected_sinkhorn/checkpoints/')\n",
        "\n",
        "# for epoch in range(start_epoch, start_epoch+1):\n",
        "#     if epoch%3 == 0:\n",
        "#       # testacc = testcifar()\n",
        "#       attackacc = test_attackcifar()\n",
        "    # traincifar(testacc,attackacc,epoch)\n",
        "#     # scheduler.step()\n",
        "    \n",
        "!zip -r /content/gdrive/MyDrive/Colab_Notebooks/Images/CIFAR.zip /content/gdrive/MyDrive/Colab_Notebooks/Images/CIFAR    "
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./drive/MyDrive/projected_sinkhorn/dataset/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa1638c7131a45acbd4ce0510ce1327b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./drive/MyDrive/projected_sinkhorn/dataset/cifar-10-python.tar.gz to ./drive/MyDrive/projected_sinkhorn/dataset/\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-158-a3f823726603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m   \u001b[0mnew_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'net'"
          ]
        }
      ]
    }
  ]
}